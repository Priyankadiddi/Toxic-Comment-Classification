{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jigsaw_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w_RwJCE4kOPC",
        "outputId": "b765ba08-d2eb-4f86-86e5-b9cc5f16bab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install emoji\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "from wordcloud import WordCloud\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score,roc_curve,auc,confusion_matrix,classification_report,log_loss\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn import preprocessing\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import re\n",
        "from gensim.models import KeyedVectors \n",
        "from wordcloud import WordCloud\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.manifold import TSNE \n",
        "from sklearn.preprocessing import Normalizer \n",
        "import plotly.offline as py\n",
        "import plotly\n",
        "from plotly.offline import *\n",
        "py.init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "import plotly.tools as tls\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import emoji\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from gensim.models import KeyedVectors\n",
        "from tensorflow.keras.utils import plot_model \n",
        "!pip install pyLDAvis\n",
        "from pprint import pprint\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "# spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim  # don't skip this\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Enable logging for gensim - optional\n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from gensim.models import LdaModel\n",
        "import tensorflow as tf\n",
        "from textblob import TextBlob, Word, Blobber\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "!pip show tensorflow\n",
        "!pip install plot_model\n",
        "!pip install tensorboardcolab\n",
        "%load_ext tensorboard\n",
        "!rm -rf ./logs/ \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 21.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 1.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=c4b5063117a76bbbd6dccd1fe281d1b1b78aa51da0655bc965c489a49feb9f3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-0.5.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting pyLDAvis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/3a/af82e070a8a96e13217c8f362f9a73e82d61ac8fff3a2561946a97f96266/pyLDAvis-2.1.2.tar.gz (1.6MB)\n",
            "\r\u001b[K     |▏                               | 10kB 18.5MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |██                              | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▍                             | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |██▉                             | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███                             | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▎                            | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |████                            | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 276kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 286kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 296kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 307kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 317kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 327kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 337kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 348kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 358kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 368kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 378kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 389kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 399kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 409kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 419kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 430kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 440kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 450kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 460kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 471kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 481kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 491kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 501kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 512kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 522kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 532kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 542kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 552kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 563kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 573kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 583kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 593kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 604kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 614kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 624kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 634kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 645kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 655kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 665kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 675kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 686kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 696kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 706kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 716kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 727kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 737kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 747kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 757kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 768kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 778kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 788kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 798kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 808kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 819kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 829kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 839kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 849kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 860kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 870kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 880kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 890kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 901kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 911kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 921kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 931kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 942kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 952kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 962kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 972kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 983kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 993kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.0MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.5MB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.6MB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.34.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.18.4)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (1.0.3)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.15.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.11.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (2.7.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (3.6.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Collecting funcy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/4b/6ffa76544e46614123de31574ad95758c421aae391a1764921b8a81e1eae/funcy-1.14.tar.gz (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 14.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (8.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.12.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (19.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->pyLDAvis) (47.1.1)\n",
            "Building wheels for collected packages: pyLDAvis, funcy\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-2.1.2-py2.py3-none-any.whl size=97711 sha256=7db75b3388d35c1832f348d863b522f613c20860e38933419afbc6f1ccb803e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/71/24/513a99e58bb6b8465bae4d2d5e9dba8f0bef8179e3051ac414\n",
            "  Building wheel for funcy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funcy: filename=funcy-1.14-py2.py3-none-any.whl size=32042 sha256=8d842ad19f7ff6bba106ad4b5232d4b7395e3fa64819d8ad8bb7bbf332848e18\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/5a/d8/1d875df03deae6f178dfdf70238cca33f948ef8a6f5209f2eb\n",
            "Successfully built pyLDAvis funcy\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-1.14 pyLDAvis-2.1.2\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "Name: tensorflow\n",
            "Version: 2.2.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: astunparse, scipy, absl-py, keras-preprocessing, six, gast, tensorflow-estimator, wrapt, termcolor, grpcio, google-pasta, h5py, tensorboard, wheel, protobuf, opt-einsum, numpy\n",
            "Required-by: fancyimpute\n",
            "Collecting plot_model\n",
            "  Downloading https://files.pythonhosted.org/packages/62/b8/0967e30391a7c07002c5e7bca868763dcfd26808dcb13aba052a737aa01d/plot_model-0.20-py3-none-any.whl\n",
            "Installing collected packages: plot-model\n",
            "Successfully installed plot-model-0.20\n",
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4nMbE-MMB1NM",
        "outputId": "f83ecd65-7086-4905-8131-7518b3448ff8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SS30IFwIGNyY",
        "colab": {}
      },
      "source": [
        "# Loading the train data into pandas dataframe\n",
        "train = pd.read_csv('/content/drive/My Drive/train.csv')\n",
        "# Loading the test data into pandas dataframe\n",
        "test = pd.read_csv('/content/drive/My Drive/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "obDpO_tbkVJX"
      },
      "source": [
        "# Deep Learning model 1: Using Only Text Feature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QO1kKmRp3TZo"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=10hz-srvxju8mZs-ju3164v2bW1lRd_3j)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtIWd2cFAF8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.kaggle.com/thousandvoices/simple-lstm\n",
        "EMBEDDING_FILES = [\n",
        "    '/content/drive/My Drive/jigsaw/crawl-300d-2M.gensim',\n",
        "    '/content/drive/My Drive/jigsaw/glove.840B.300d.gensim'\n",
        "]\n",
        "NUM_MODELS = 2\n",
        "BATCH_SIZE = 512\n",
        "LSTM_UNITS = 128\n",
        "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
        "EPOCHS = 4\n",
        "MAX_LEN = 220\n",
        "IDENTITY_COLUMNS = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish', 'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
        "\n",
        "AUX_COLUMNS = ['target', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat']\n",
        "TEXT_COLUMN = 'comment_text'\n",
        "TARGET_COLUMN='target'\n",
        "CHARS_TO_REMOVE = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—'\n",
        "\n",
        "X_train, X_te = train_test_split(train, test_size=0.1,random_state=42)\n",
        "X_train, X_cv = train_test_split(X_train, test_size=0.1,random_state=42)\n",
        "\n",
        "x_train = X_train[TEXT_COLUMN].astype(str)\n",
        "y_train = X_train[TARGET_COLUMN].values\n",
        "\n",
        "\n",
        "x_cv = X_cv[TEXT_COLUMN].astype(str)\n",
        "y_cv = X_cv[TARGET_COLUMN].values\n",
        "\n",
        "x_te = X_te[TEXT_COLUMN].astype(str)\n",
        "y_te = X_te[TARGET_COLUMN].values\n",
        "\n",
        "for column in IDENTITY_COLUMNS + [TARGET_COLUMN]:\n",
        "    X_train[column] = np.where(X_train[column] >= 0.5, True, False)\n",
        "    X_cv[column] = np.where(X_cv[column] >= 0.5, True, False)\n",
        "    X_te[column] = np.where(X_te[column] >= 0.5, True, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1qOmNEDnlPBr",
        "colab": {}
      },
      "source": [
        "def build_matrix(word_index, path):\n",
        "    embedding_index = KeyedVectors.load(path, mmap='r')\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "    for word, i in word_index.items():\n",
        "        for candidate in [word, word.lower()]:\n",
        "            if candidate in embedding_index:\n",
        "                embedding_matrix[i] = embedding_index[candidate]\n",
        "                break\n",
        "    return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ljrQkHQjOBmr",
        "colab": {}
      },
      "source": [
        "tokenizer = text.Tokenizer(filters=CHARS_TO_REMOVE, lower=False)\n",
        "tokenizer.fit_on_texts(list(x_train))\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_cv = tokenizer.texts_to_sequences(x_cv)\n",
        "x_te = tokenizer.texts_to_sequences(x_te)\n",
        "\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=MAX_LEN)\n",
        "x_cv = sequence.pad_sequences(x_cv, maxlen=MAX_LEN)\n",
        "x_te = sequence.pad_sequences(x_te, maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdqE6ktcAP3-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pickle.dump(tokenizer,open(\"/content/drive/My Drive/jigsaw/dltokenizer\",\"wb\"))\n",
        "sample_weights = np.ones(len(x_train), dtype=np.float32)\n",
        "sample_weights += X_train[IDENTITY_COLUMNS].sum(axis=1)\n",
        "sample_weights += X_train[TARGET_COLUMN] * (~X_train[IDENTITY_COLUMNS]).sum(axis=1)\n",
        "sample_weights += (~X_train[TARGET_COLUMN]) * X_train[IDENTITY_COLUMNS].sum(axis=1) * 5\n",
        "sample_weights /= sample_weights.mean()\n",
        "\n",
        "embedding_matrix = np.concatenate([build_matrix(tokenizer.word_index, f) for f in EMBEDDING_FILES], axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrfIz2x8Pp4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def build_model(embedding_matrix):\n",
        "    words = Input(shape=(None,))\n",
        "    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n",
        "    x = SpatialDropout1D(0.2)(x)\n",
        "    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "\n",
        "    hidden = concatenate([\n",
        "        GlobalMaxPooling1D()(x),\n",
        "        GlobalAveragePooling1D()(x),\n",
        "    ])\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
        "    hidden = add([hidden, Dense(DENSE_HIDDEN_UNITS, activation='relu')(hidden)])\n",
        "    result = Dense(1, activation='sigmoid')(hidden)\n",
        "    \n",
        "    model = Model(inputs=words, outputs=result)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    #plot_model(model, to_file='/content/drive/My Drive/jigsaw/model1.png', show_shapes=True) \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIIxr3xIKV5t",
        "colab_type": "code",
        "outputId": "ecc4a9aa-7384-41a4-ba83-53f630dbe12e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "!pip show tensorflow\n",
        "!pip install plot_model\n",
        "!pip install tensorboardcolab\n",
        "%load_ext tensorboard\n",
        "!rm -rf ./logs/ \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.2.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: tensorboard, absl-py, keras-preprocessing, opt-einsum, h5py, grpcio, numpy, gast, protobuf, tensorflow-estimator, termcolor, astunparse, wrapt, six, wheel, google-pasta, scipy\n",
            "Required-by: fancyimpute\n",
            "Requirement already satisfied: plot_model in /usr/local/lib/python3.6/dist-packages (0.20)\n",
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0Ibh8O-Pv7G",
        "colab_type": "code",
        "outputId": "68ee1407-9932-4953-c3d4-72c9a5d6eeff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "checkpoint_predictions = []\n",
        "weights = []\n",
        "checkpoint = tensorflow.keras.callbacks.ModelCheckpoint('/content/drive/My Drive/jigsaw/Model11.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min') \n",
        "log_dir=\"/content/drive/My Drive/jigsaw/Model11/logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,write_grads=True)\n",
        "\n",
        "model = build_model(embedding_matrix)\n",
        "model.fit(x_train, y_train,batch_size=BATCH_SIZE,epochs=5,verbose=2,validation_data=(x_cv,y_cv),callbacks=[tensorboard_callback,checkpoint],sample_weight=[sample_weights.values, np.ones_like(sample_weights)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-31 10:31:57,422 : WARNING : `write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.24552, saving model to /content/drive/My Drive/jigsaw/Model11.hdf5\n",
            "2856/2856 - 829s - loss: 0.4226 - val_loss: 0.2455\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.24552 to 0.24449, saving model to /content/drive/My Drive/jigsaw/Model11.hdf5\n",
            "2856/2856 - 813s - loss: 0.4088 - val_loss: 0.2445\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.24449 to 0.24227, saving model to /content/drive/My Drive/jigsaw/Model11.hdf5\n",
            "2856/2856 - 813s - loss: 0.4039 - val_loss: 0.2423\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.24227\n",
            "2856/2856 - 809s - loss: 0.3998 - val_loss: 0.2475\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.24227\n",
            "2856/2856 - 808s - loss: 0.3963 - val_loss: 0.2436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa320058208>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26ny3SOtzFgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir='/content/drive/My Drive/jigsaw/Model11/logs/fit'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdrPFd6fikXh",
        "colab_type": "code",
        "outputId": "22da757c-45c8-4eb6-a61c-e4ef1942b00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# load the model \n",
        "model1=tensorflow.keras.models.load_model('/content/drive/My Drive/jigsaw/Model11.hdf5')\n",
        "\n",
        "predictions=model1.predict(x_te, batch_size=2048).flatten()\n",
        "MODEL_NAME = 'score'\n",
        "X_te[MODEL_NAME] = predictions\n",
        "bias_metrics_df = compute_bias_metrics_for_model(X_te, IDENTITY_COLUMNS, MODEL_NAME, TARGET_COLUMN)\n",
        "get_final_metric(bias_metrics_df, calculate_overall_auc(X_te, MODEL_NAME))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9319064728629746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBEkOOuwOkgY",
        "colab_type": "text"
      },
      "source": [
        "# **Deep Learning Model 2 : Text feature + Additional Features**\n",
        "\n",
        "Additional Features:\n",
        "- topic features\n",
        "- positive word count\n",
        "- negative word count\n",
        "- sentiment of each comment\n",
        "- word count,character count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcGoknUJ8gO9",
        "colab_type": "text"
      },
      "source": [
        "# Train cv split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrQnalcV8k0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_te = train_test_split(train, test_size=0.1,random_state=42)\n",
        "\n",
        "X_train, X_cv = train_test_split(X_train, test_size=0.1,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ibY77IhtQXo",
        "colab_type": "text"
      },
      "source": [
        "# Topic modeling ( Unsupervised Clustering Method )\n",
        "- LDA ( Latent Dirichlet Allocation ) is an unsupervised machine-learning model that automatically identify topics present in a text object and to derive hidden patterns exhibited by a text corpus. Thus, assisting better decision making.\n",
        "- we will model our clean_text into 5 different topics and then take these topics as features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIMoj_4qCOCg",
        "colab_type": "code",
        "outputId": "6790cf9e-07c5-4234-f024-964b74c464bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#https://github.com/sonalijathar01/Toxic-comment-classification/blob/master/Jigsaw_UnIntended_Bias_Toxicity_Classification-Org.ipynb\n",
        "%%time\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "# Tokenize and lemmatize\n",
        "def preprocess(text):\n",
        "    '''this is for preprocessing text using gensim.utils.simple_preprocess() function'''\n",
        "    result=[]\n",
        "    for token in gensim.utils.simple_preprocess(text) :\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "            \n",
        "    return result\n",
        "\n",
        "\n",
        "data = X_train.clean_text.values.tolist()\n",
        "processed_docs = []\n",
        "for doc in data:\n",
        "    processed_docs.append(preprocess(doc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 11min 3s, sys: 2.11 s, total: 11min 5s\n",
            "Wall time: 11min 5s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPhsogOH7cfS",
        "colab_type": "text"
      },
      "source": [
        "# Create the Dictionary and Corpus needed for Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5NaCmyLrP_D",
        "colab_type": "code",
        "outputId": "fe61c61e-9267-4f00-c785-369029a029af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%time\n",
        "# Create Dictionary\n",
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "\n",
        "# Create Corpus\n",
        "texts = processed_docs\n",
        "\n",
        "# Term Document Frequency\n",
        "# Gensim creates a unique id for each word in the document. The produced corpus shown above is a mapping of (word_id, word_frequency).\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]]\n",
            "CPU times: user 1min 12s, sys: 1.14 s, total: 1min 13s\n",
            "Wall time: 1min 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWMq69TVAb5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(dictionary,open('/content/drive/My Drive/jigsaw/dictionary','wb'))\n",
        "#dictionary=pickle.load(open('/content/drive/My Drive/jigsaw/dictionary','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQFr9Tc57oBA",
        "colab_type": "code",
        "outputId": "99d1db42-e7b3-4fd4-f48f-0113e8b076fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(dictionary[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('alaska', 1),\n",
              "  ('career', 1),\n",
              "  ('collegi', 1),\n",
              "  ('good', 1),\n",
              "  ('gymnast', 1),\n",
              "  ('luck', 1),\n",
              "  ('repres', 1),\n",
              "  ('thank', 1)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWlQa6wD7qDo",
        "colab_type": "text"
      },
      "source": [
        "# Building topic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG0vIiCdrP7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this code took me 10 hours to run\n",
        "\n",
        "# Build LDA model\n",
        "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, random_state=100, update_every=1,\n",
        "                                           chunksize=100, passes=10, alpha='auto', per_word_topics=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8tDg_UzYNXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pickle.dump(lda_model,open('/content/drive/My Drive/jigsaw/ldamodelall','wb'))\n",
        "lda_model=pickle.load(open('/content/drive/My Drive/jigsaw/ldamodelall','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjWOv5fiDSb2",
        "colab_type": "code",
        "outputId": "f54d0280-49b1-45f6-928c-0a471e845bfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Coherence Score:  0.4943335322897525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4All3BgYkCw",
        "colab_type": "code",
        "outputId": "f577679e-95ff-484f-f00c-b80a1ea0ae42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Print the Keyword in the 5 topics\n",
        "print(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.012*\"life\" + 0.011*\"million\" + 0.011*\"question\" + 0.009*\"women\" + 0.009*\"church\" + 0.007*\"line\" + 0.007*\"pass\" + 0.007*\"job\" + 0.006*\"truth\" + 0.006*\"exact\"'), (1, '0.022*\"state\" + 0.018*\"govern\" + 0.016*\"money\" + 0.012*\"chang\" + 0.012*\"public\" + 0.011*\"care\" + 0.011*\"polit\" + 0.009*\"busi\" + 0.009*\"cost\" + 0.009*\"pay\"'), (2, '0.039*\"trump\" + 0.022*\"say\" + 0.014*\"like\" + 0.014*\"comment\" + 0.013*\"support\" + 0.013*\"fact\" + 0.011*\"presid\" + 0.011*\"read\" + 0.011*\"link\" + 0.010*\"articl\"'), (3, '0.028*\"peopl\" + 0.018*\"think\" + 0.017*\"know\" + 0.016*\"right\" + 0.013*\"want\" + 0.011*\"thing\" + 0.009*\"countri\" + 0.009*\"vote\" + 0.008*\"leav\" + 0.008*\"person\"'), (4, '0.023*\"time\" + 0.023*\"like\" + 0.023*\"year\" + 0.017*\"go\" + 0.016*\"good\" + 0.014*\"need\" + 0.012*\"come\" + 0.012*\"work\" + 0.011*\"live\" + 0.011*\"look\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckts5T58G0VJ",
        "colab_type": "code",
        "outputId": "246ee7a4-4e41-464c-f87e-b91cc99df7fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        }
      },
      "source": [
        "# Visualize the topics on train\n",
        " pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
        "vis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1381397674756254403532750173\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1381397674756254403532750173_data = {\"mdsDat\": {\"x\": [0.3164183086326352, -0.11616463895932194, 0.07698798896573449, -0.32885623914641177, 0.05161458050736435], \"y\": [-0.126553711872118, -0.19825612424320377, -0.07679532176871919, -0.005774939588660706, 0.4073800974727018], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [29.260766983032227, 22.933717727661133, 18.248371124267578, 16.829971313476562, 12.727178573608398]}, \"tinfo\": {\"Term\": [\"trump\", \"peopl\", \"time\", \"year\", \"like\", \"state\", \"think\", \"say\", \"know\", \"go\", \"govern\", \"right\", \"good\", \"money\", \"want\", \"comment\", \"need\", \"thing\", \"chang\", \"fact\", \"public\", \"live\", \"look\", \"come\", \"care\", \"work\", \"support\", \"presid\", \"read\", \"polit\", \"peopl\", \"think\", \"know\", \"right\", \"want\", \"thing\", \"countri\", \"vote\", \"leav\", \"person\", \"mean\", \"elect\", \"liber\", \"believ\", \"world\", \"issu\", \"american\", \"actual\", \"tell\", \"parti\", \"give\", \"nation\", \"differ\", \"reason\", \"agre\", \"stop\", \"mayb\", \"case\", \"power\", \"tri\", \"get\", \"canada\", \"time\", \"year\", \"go\", \"good\", \"live\", \"look\", \"canadian\", \"better\", \"great\", \"help\", \"long\", \"start\", \"thank\", \"famili\", \"place\", \"littl\", \"home\", \"best\", \"hope\", \"play\", \"away\", \"trudeau\", \"children\", \"wonder\", \"probabl\", \"ignor\", \"servic\", \"see\", \"market\", \"drive\", \"come\", \"like\", \"make\", \"need\", \"work\", \"take\", \"state\", \"govern\", \"money\", \"chang\", \"public\", \"care\", \"polit\", \"busi\", \"cost\", \"pay\", \"hous\", \"school\", \"citi\", \"build\", \"alaska\", \"spend\", \"wrong\", \"tax\", \"fund\", \"major\", \"health\", \"hard\", \"feder\", \"increas\", \"provid\", \"immigr\", \"compani\", \"educ\", \"incom\", \"current\", \"need\", \"canada\", \"work\", \"trump\", \"say\", \"comment\", \"fact\", \"presid\", \"read\", \"link\", \"articl\", \"post\", \"sure\", \"call\", \"obama\", \"white\", \"republican\", \"democrat\", \"news\", \"write\", \"stori\", \"report\", \"word\", \"matter\", \"continu\", \"america\", \"conserv\", \"opinion\", \"stand\", \"inform\", \"hillari\", \"correct\", \"mind\", \"support\", \"point\", \"lose\", \"like\", \"life\", \"million\", \"question\", \"women\", \"church\", \"line\", \"pass\", \"job\", \"truth\", \"exact\", \"choos\", \"ask\", \"member\", \"senat\", \"sens\", \"answer\", \"cathol\", \"societi\", \"week\", \"accept\", \"meet\", \"experi\", \"suggest\", \"fight\", \"road\", \"self\", \"common\", \"legisl\", \"sign\", \"natur\"], \"Freq\": [223988.0, 283228.0, 181322.0, 177659.0, 263286.0, 136079.0, 181153.0, 124527.0, 172653.0, 134458.0, 114889.0, 156027.0, 127799.0, 96841.0, 133098.0, 81463.0, 151568.0, 107121.0, 76646.0, 73158.0, 73581.0, 84834.0, 84761.0, 112872.0, 71538.0, 129662.0, 83825.0, 65971.0, 65730.0, 68109.0, 283227.84375, 181152.859375, 172652.75, 156026.9375, 133097.671875, 107120.8046875, 91438.140625, 89588.1328125, 77944.890625, 76608.7578125, 71681.5234375, 70053.125, 69476.5, 68887.359375, 69202.4140625, 66906.7734375, 65802.078125, 66153.328125, 64250.05078125, 60303.38671875, 60628.8671875, 59278.51171875, 58415.21875, 57402.32421875, 50299.32421875, 48898.90625, 48787.44140625, 45305.25, 44927.42578125, 43880.71875, 49318.95703125, 49692.07421875, 181322.09375, 177658.375, 134457.25, 127798.9375, 84833.1875, 84760.296875, 65907.6015625, 63691.36328125, 56115.81640625, 54780.8046875, 54416.07421875, 52630.82421875, 50902.30078125, 49128.7734375, 47082.4765625, 44500.10546875, 44263.1015625, 42800.33984375, 41077.01171875, 38200.03515625, 36643.19921875, 35895.8203125, 34498.35546875, 33991.2578125, 33027.4765625, 32944.44140625, 32598.115234375, 31089.513671875, 30350.28125, 29480.73828125, 97546.90625, 179087.9375, 58853.3359375, 110953.96875, 95969.5078125, 55047.2421875, 136078.390625, 114888.4921875, 96840.6484375, 76645.4140625, 73580.7890625, 71537.734375, 68108.5625, 56416.43359375, 54969.90625, 53323.078125, 51928.53515625, 49669.5390625, 45303.30859375, 44367.8046875, 44037.890625, 43533.1015625, 44220.98046875, 42771.296875, 42602.4765625, 41059.2265625, 38541.91015625, 38034.76171875, 37400.84375, 35205.84765625, 34985.0703125, 34019.5625, 33372.1328125, 33334.12890625, 32417.201171875, 32550.419921875, 40613.9921875, 34882.15234375, 33692.6171875, 223987.546875, 124526.4921875, 81462.328125, 73157.2578125, 65970.359375, 65729.2109375, 64131.95703125, 56770.62109375, 55343.2578125, 55278.96875, 49933.11328125, 48504.578125, 48499.7578125, 46682.93359375, 46539.87109375, 44478.99609375, 43677.58203125, 39846.55078125, 38135.3984375, 37733.44140625, 37642.18359375, 37800.828125, 35213.6953125, 33517.65625, 32989.68359375, 32789.41796875, 30437.31640625, 28139.05078125, 28116.271484375, 27312.435546875, 73411.0, 52872.86328125, 37382.03515625, 81678.9609375, 51491.1328125, 48278.10546875, 46462.7578125, 40846.74609375, 37748.5625, 31262.025390625, 29127.837890625, 28724.52734375, 28108.8671875, 26083.98828125, 25277.21484375, 24303.28125, 23805.958984375, 23866.763671875, 23771.77734375, 23460.453125, 23033.0703125, 23024.330078125, 22981.990234375, 22572.46875, 22459.015625, 22134.45703125, 21991.8984375, 22072.97265625, 21576.298828125, 21266.244140625, 20741.86328125, 20882.07421875, 20782.708984375, 20565.265625], \"Total\": [223988.0, 283228.0, 181322.0, 177659.0, 263286.0, 136079.0, 181153.0, 124527.0, 172653.0, 134458.0, 114889.0, 156027.0, 127799.0, 96841.0, 133098.0, 81463.0, 151568.0, 107121.0, 76646.0, 73158.0, 73581.0, 84834.0, 84761.0, 112872.0, 71538.0, 129662.0, 83825.0, 65971.0, 65730.0, 68109.0, 283228.65625, 181153.671875, 172653.5625, 156027.75, 133098.484375, 107121.625, 91438.953125, 89588.9453125, 77945.7109375, 76609.578125, 71682.34375, 70053.9375, 69477.3125, 68888.1796875, 69203.234375, 66907.59375, 65802.890625, 66154.140625, 64250.87109375, 60304.203125, 60629.6875, 59279.328125, 58416.0390625, 57403.140625, 50300.140625, 48899.7265625, 48788.26171875, 45306.06640625, 44928.24609375, 43881.5390625, 59097.046875, 84574.8359375, 181322.90625, 177659.1875, 134458.0625, 127799.75, 84834.0078125, 84761.109375, 65908.4140625, 63692.1796875, 56116.6328125, 54781.62109375, 54416.890625, 52631.640625, 50903.11328125, 49129.58984375, 47083.29296875, 44500.921875, 44263.9140625, 42801.15625, 41077.828125, 38200.84765625, 36644.015625, 35896.63671875, 34499.1796875, 33992.07421875, 33028.29296875, 32945.26171875, 32598.931640625, 31090.328125, 30351.095703125, 29481.55078125, 112872.9140625, 263286.5, 68405.0859375, 151568.5625, 129662.7421875, 71010.765625, 136079.203125, 114889.3046875, 96841.4609375, 76646.2421875, 73581.609375, 71538.5546875, 68109.390625, 56417.24609375, 54970.71875, 53323.890625, 51929.35546875, 49670.35546875, 45304.12109375, 44368.62109375, 44038.703125, 43533.9140625, 44221.80859375, 42772.10546875, 42603.2890625, 41060.046875, 38542.72265625, 38035.5859375, 37401.65625, 35206.66015625, 34985.890625, 34020.3828125, 33372.94140625, 33334.94140625, 32418.009765625, 32551.240234375, 151568.5625, 84574.8359375, 129662.7421875, 223988.359375, 124527.3125, 81463.140625, 73158.078125, 65971.1640625, 65730.03125, 64132.7734375, 56771.4375, 55344.07421875, 55279.7890625, 49933.9296875, 48505.38671875, 48500.57421875, 46683.74609375, 46540.68359375, 44479.80859375, 43678.3984375, 39847.3671875, 38136.21484375, 37734.2578125, 37643.00390625, 37801.65234375, 35214.51171875, 33518.47265625, 32990.5, 32790.234375, 30438.134765625, 28139.861328125, 28117.09375, 27313.255859375, 83825.9765625, 72599.1015625, 44564.171875, 263286.5, 51491.9453125, 48278.92578125, 46463.5703125, 40847.55078125, 37749.36328125, 31262.841796875, 29128.654296875, 28725.34375, 28109.6796875, 26084.8046875, 25278.029296875, 24304.095703125, 23806.771484375, 23867.580078125, 23772.58984375, 23461.263671875, 23033.873046875, 23025.140625, 22982.806640625, 22573.28125, 22459.83203125, 22135.267578125, 21992.7109375, 22073.787109375, 21577.11328125, 21267.0546875, 20742.67578125, 20882.892578125, 20783.525390625, 20566.076171875], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.5641000270843506, -4.011000156402588, -4.059000015258789, -4.160299777984619, -4.319200038909912, -4.536399841308594, -4.694699764251709, -4.715099811553955, -4.854300022125244, -4.871600151062012, -4.9380998611450195, -4.961100101470947, -4.969299793243408, -4.977799892425537, -4.973299980163574, -5.006999969482422, -5.02370023727417, -5.0183000564575195, -5.047500133514404, -5.110899925231934, -5.105500221252441, -5.1280999183654785, -5.1427001953125, -5.160200119018555, -5.292300224304199, -5.3206000328063965, -5.322800159454346, -5.396900177001953, -5.405300140380859, -5.428800106048584, -5.311999797821045, -5.304500102996826, -3.766400098800659, -3.786799907684326, -4.065400123596191, -4.116199970245361, -4.526000022888184, -4.526800155639648, -4.77839994430542, -4.812600135803223, -4.939300060272217, -4.9633002281188965, -4.96999979019165, -5.003399848937988, -5.036799907684326, -5.072199821472168, -5.114799976348877, -5.171199798583984, -5.176499843597412, -5.210100173950195, -5.251200199127197, -5.323800086975098, -5.3653998374938965, -5.386099815368652, -5.42579984664917, -5.4405999183654785, -5.469299793243408, -5.47189998626709, -5.482399940490723, -5.529799938201904, -5.553899765014648, -5.582900047302246, -4.386300086975098, -3.7788000106811523, -4.891600131988525, -4.257599830627441, -4.402599811553955, -4.958499908447266, -3.824899911880493, -3.9941999912261963, -4.16510009765625, -4.39900016784668, -4.439799785614014, -4.467899799346924, -4.517000198364258, -4.705399990081787, -4.731400012969971, -4.7617998123168945, -4.788300037384033, -4.832799911499023, -4.924799919128418, -4.9456000328063965, -4.953100204467773, -4.964600086212158, -4.94890022277832, -4.9822998046875, -4.986199855804443, -5.023099899291992, -5.086400032043457, -5.099599838256836, -5.116399765014648, -5.1768999099731445, -5.183199882507324, -5.21120023727417, -5.230400085449219, -5.231599807739258, -5.259500026702881, -5.25540018081665, -5.033999919891357, -5.186200141906738, -5.220900058746338, -3.2455999851226807, -3.83270001411438, -4.2571001052856445, -4.36460018157959, -4.4679999351501465, -4.471700191497803, -4.496300220489502, -4.618199825286865, -4.643700122833252, -4.644800186157227, -4.746500015258789, -4.775599956512451, -4.775700092315674, -4.813799858093262, -4.81689977645874, -4.862199783325195, -4.88040018081665, -4.9721999168396, -5.01609992980957, -5.026700019836426, -5.029099941253662, -5.024899959564209, -5.095799922943115, -5.145199775695801, -5.160999774932861, -5.167099952697754, -5.241600036621094, -5.320099830627441, -5.320899963378906, -5.349899768829346, -4.361199855804443, -4.689300060272217, -5.035999774932861, -4.25439977645874, -4.436399936676025, -4.500800132751465, -4.5391998291015625, -4.668000221252441, -4.7469000816345215, -4.935400009155273, -5.006100177764893, -5.020100116729736, -5.0416998863220215, -5.116499900817871, -5.147900104522705, -5.18720006942749, -5.207900047302246, -5.2052998542785645, -5.2093000411987305, -5.222499847412109, -5.240900039672852, -5.241300106048584, -5.243100166320801, -5.261099815368652, -5.26609992980957, -5.280700206756592, -5.287099838256836, -5.2835001945495605, -5.30620002746582, -5.320700168609619, -5.345699787139893, -5.338900089263916, -5.343699932098389, -5.3541998863220215], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.2288999557495117, 1.0480999946594238, 0.6970999836921692, 1.472599983215332, 1.472599983215332, 1.472599983215332, 1.472599983215332, 1.472599983215332, 1.472599983215332, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.472499966621399, 1.3265999555587769, 1.0872000455856323, 1.3221999406814575, 1.160599946975708, 1.1717000007629395, 1.217900037765503, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 1.7010999917984009, 0.38420000672340393, 0.8154000043869019, 0.35339999198913574, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.781999945640564, 1.6492999792099, 1.464900016784668, 1.6062999963760376, 0.6115999817848206, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254, 2.0613999366760254]}, \"token.table\": {\"Topic\": [5, 1, 1, 3, 4, 1, 5, 4, 5, 2, 1, 2, 2, 3, 3, 4, 1, 3, 2, 3, 1, 5, 3, 2, 5, 5, 3, 1, 2, 4, 5, 3, 4, 4, 4, 3, 1, 3, 4, 1, 2, 3, 1, 5, 5, 4, 2, 3, 5, 3, 1, 3, 1, 2, 2, 3, 2, 3, 3, 2, 4, 2, 2, 3, 2, 3, 3, 3, 4, 1, 5, 1, 1, 5, 1, 5, 1, 2, 4, 5, 4, 2, 2, 2, 2, 3, 4, 3, 2, 4, 2, 4, 1, 1, 5, 5, 5, 4, 3, 1, 5, 2, 3, 4, 4, 4, 1, 5, 3, 1, 1, 2, 2, 2, 4, 3, 4, 1, 4, 2, 3, 3, 5, 4, 1, 4, 4, 1, 5, 4, 3, 2, 5, 5, 5, 2, 5, 5, 3, 4, 2, 3, 1, 4, 5, 3, 4, 4, 1, 2, 3, 1, 2, 1, 1, 2, 1, 2, 4, 5, 1, 1, 5, 4, 5, 2, 4, 2, 3, 1, 4, 3, 2], \"Freq\": [0.9999432563781738, 0.9999827742576599, 0.9999773502349854, 0.9999840259552002, 0.9999854564666748, 0.999986469745636, 0.999946117401123, 0.999992311000824, 0.9999549388885498, 0.9999722838401794, 0.9999828934669495, 0.9999729990959167, 0.9999814629554749, 0.9999859929084778, 0.9999778866767883, 0.9999814033508301, 0.5875506401062012, 0.4124394655227661, 0.9999937415122986, 0.9999922513961792, 0.9999764561653137, 0.9999620914459229, 0.9999837875366211, 0.9999657869338989, 0.9999592900276184, 0.9999904036521912, 0.9999752640724182, 0.13577216863632202, 0.8642197251319885, 0.9999859929084778, 0.9999673962593079, 0.9999718070030212, 0.9999858736991882, 0.9999827146530151, 0.9999610781669617, 0.9999869465827942, 0.9999895691871643, 0.9999619126319885, 0.9999853372573853, 0.9999822378158569, 0.9999813437461853, 0.9999717473983765, 0.9999865889549255, 0.9999691247940063, 0.9999427199363708, 0.9999852776527405, 0.9999880194664001, 0.999982476234436, 0.9999643564224243, 0.9999697208404541, 0.8345425724983215, 0.16543973982334137, 0.9999886751174927, 0.9999920725822449, 0.999994158744812, 0.9999886155128479, 0.9999887347221375, 0.999984622001648, 0.9999812245368958, 0.9999886751174927, 0.9999693632125854, 0.9999793767929077, 0.9999798536300659, 0.9999931454658508, 0.9999616742134094, 0.9999887347221375, 0.9999688267707825, 0.9999812245368958, 0.9999627470970154, 0.9999911189079285, 0.9999880194664001, 0.9999967217445374, 0.9999908804893494, 0.999957263469696, 0.9999811053276062, 0.9999816417694092, 0.009567524306476116, 0.6802020072937012, 0.3102285861968994, 0.9999730587005615, 0.9999879598617554, 0.9999792575836182, 0.9999881386756897, 0.9999836087226868, 0.9999868869781494, 0.16116085648536682, 0.8388352990150452, 0.9999744892120361, 0.8603600263595581, 0.13962411880493164, 0.9999638795852661, 0.9999733567237854, 0.9999741315841675, 0.999995231628418, 0.9999629259109497, 0.9999675750732422, 0.9999808073043823, 0.9999540448188782, 0.999995231628418, 0.9999944567680359, 0.9999476671218872, 0.7320383191108704, 0.2679579555988312, 0.9999818205833435, 0.9999920129776001, 0.999984860420227, 0.9999800324440002, 0.9999775290489197, 0.9999833106994629, 0.9999976754188538, 0.9999924302101135, 0.9999725222587585, 0.9999778270721436, 0.2717113494873047, 0.7282872200012207, 0.9999942779541016, 0.9999805688858032, 0.9999722838401794, 0.9999823570251465, 0.9999608397483826, 0.9999745488166809, 0.9999917149543762, 0.9999877214431763, 0.9999843239784241, 0.9999801516532898, 0.9999681711196899, 0.9999840259552002, 0.9999951720237732, 0.9999483823776245, 0.9999894499778748, 0.999992847442627, 0.9999894499778748, 0.9999504089355469, 0.9999756813049316, 0.9999752044677734, 0.9999714493751526, 0.9999747276306152, 0.9999504685401917, 0.9999790191650391, 0.999962329864502, 0.9999878406524658, 0.9999911785125732, 0.9999851584434509, 0.9999907612800598, 0.9999676942825317, 0.12423356622457504, 0.8757547736167908, 0.9999857544898987, 0.22479690611362457, 0.7751923203468323, 0.9999741315841675, 0.999986469745636, 0.9999781250953674, 0.999994158744812, 0.9999963045120239, 0.9999949932098389, 0.9999877214431763, 0.9999822378158569, 0.9999983906745911, 0.9999758005142212, 0.9999894499778748, 0.9999963641166687, 0.9999648928642273, 0.9999881386756897, 0.9999865293502808, 0.999968409538269, 0.9999666810035706, 0.7401509284973145, 0.25985103845596313, 0.9999821782112122, 0.9999908804893494, 0.999981701374054, 0.9999933242797852], \"Term\": [\"accept\", \"actual\", \"agre\", \"alaska\", \"america\", \"american\", \"answer\", \"articl\", \"ask\", \"away\", \"believ\", \"best\", \"better\", \"build\", \"busi\", \"call\", \"canada\", \"canada\", \"canadian\", \"care\", \"case\", \"cathol\", \"chang\", \"children\", \"choos\", \"church\", \"citi\", \"come\", \"come\", \"comment\", \"common\", \"compani\", \"conserv\", \"continu\", \"correct\", \"cost\", \"countri\", \"current\", \"democrat\", \"differ\", \"drive\", \"educ\", \"elect\", \"exact\", \"experi\", \"fact\", \"famili\", \"feder\", \"fight\", \"fund\", \"get\", \"get\", \"give\", \"go\", \"good\", \"govern\", \"great\", \"hard\", \"health\", \"help\", \"hillari\", \"home\", \"hope\", \"hous\", \"ignor\", \"immigr\", \"incom\", \"increas\", \"inform\", \"issu\", \"job\", \"know\", \"leav\", \"legisl\", \"liber\", \"life\", \"like\", \"like\", \"like\", \"line\", \"link\", \"littl\", \"live\", \"long\", \"look\", \"lose\", \"lose\", \"major\", \"make\", \"make\", \"market\", \"matter\", \"mayb\", \"mean\", \"meet\", \"member\", \"million\", \"mind\", \"money\", \"nation\", \"natur\", \"need\", \"need\", \"news\", \"obama\", \"opinion\", \"parti\", \"pass\", \"pay\", \"peopl\", \"person\", \"place\", \"play\", \"point\", \"point\", \"polit\", \"post\", \"power\", \"presid\", \"probabl\", \"provid\", \"public\", \"question\", \"read\", \"reason\", \"report\", \"republican\", \"right\", \"road\", \"say\", \"school\", \"see\", \"self\", \"senat\", \"sens\", \"servic\", \"sign\", \"societi\", \"spend\", \"stand\", \"start\", \"state\", \"stop\", \"stori\", \"suggest\", \"support\", \"support\", \"sure\", \"take\", \"take\", \"tax\", \"tell\", \"thank\", \"thing\", \"think\", \"time\", \"tri\", \"trudeau\", \"trump\", \"truth\", \"vote\", \"want\", \"week\", \"white\", \"women\", \"wonder\", \"word\", \"work\", \"work\", \"world\", \"write\", \"wrong\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 5, 2, 3, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1381397674756254403532750173\", ldavis_el1381397674756254403532750173_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1381397674756254403532750173\", ldavis_el1381397674756254403532750173_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1381397674756254403532750173\", ldavis_el1381397674756254403532750173_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "3      0.316418 -0.126554       1        1  29.260767\n",
              "4     -0.116165 -0.198256       2        1  22.933718\n",
              "1      0.076988 -0.076795       3        1  18.248371\n",
              "2     -0.328856 -0.005775       4        1  16.829971\n",
              "0      0.051615  0.407380       5        1  12.727179, topic_info=        Term           Freq          Total Category  logprob  loglift\n",
              "36     trump  223988.000000  223988.000000  Default  30.0000  30.0000\n",
              "48     peopl  283228.000000  283228.000000  Default  29.0000  29.0000\n",
              "325     time  181322.000000  181322.000000  Default  28.0000  28.0000\n",
              "225     year  177659.000000  177659.000000  Default  27.0000  27.0000\n",
              "101     like  263286.000000  263286.000000  Default  26.0000  26.0000\n",
              "...      ...            ...            ...      ...      ...      ...\n",
              "526     self   21266.244141   21267.054688   Topic5  -5.3207   2.0614\n",
              "2715  common   20741.863281   20742.675781   Topic5  -5.3457   2.0614\n",
              "146   legisl   20882.074219   20882.892578   Topic5  -5.3389   2.0614\n",
              "1805    sign   20782.708984   20783.525391   Topic5  -5.3437   2.0614\n",
              "1247   natur   20565.265625   20566.076172   Topic5  -5.3542   2.0614\n",
              "\n",
              "[195 rows x 6 columns], token_table=      Topic      Freq     Term\n",
              "term                          \n",
              "555       5  0.999943   accept\n",
              "396       1  0.999983   actual\n",
              "1313      1  0.999977     agre\n",
              "425       3  0.999984   alaska\n",
              "27        4  0.999985  america\n",
              "...     ...       ...      ...\n",
              "353       3  0.259851     work\n",
              "394       1  0.999982    world\n",
              "395       4  0.999991    write\n",
              "433       3  0.999982    wrong\n",
              "225       2  0.999993     year\n",
              "\n",
              "[173 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 5, 2, 3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9yWThW1DFKp",
        "colab_type": "text"
      },
      "source": [
        "### CV data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wl7x496pDHth",
        "colab_type": "code",
        "outputId": "98e55789-3f0a-4f31-a03b-ce0eb9424f58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%time\n",
        "data1 = X_cv.clean_text.values.tolist()\n",
        "processed_docs1 = []\n",
        "for doc in data1:\n",
        "    processed_docs1.append(preprocess(doc))\n",
        "\n",
        "print(processed_docs1[:1])\n",
        "corpus1= [dictionary.doc2bow(text) for text in processed_docs1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['fals', 'doctrin', 'attack', 'catholic', 'contain', 'articl']]\n",
            "CPU times: user 1min 19s, sys: 386 ms, total: 1min 19s\n",
            "Wall time: 1min 19s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TocTWqSFAOP",
        "colab_type": "code",
        "outputId": "67193b0f-a1f9-46f4-da5b-bd7af9887f7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        }
      },
      "source": [
        "vis = pyLDAvis.gensim.prepare(lda_model, corpus1, dictionary)\n",
        "vis"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1381397650490819287457923898\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1381397650490819287457923898_data = {\"mdsDat\": {\"x\": [0.3164183086326352, -0.11616463895932194, 0.07698798896573449, -0.32885623914641177, 0.05161458050736435], \"y\": [-0.126553711872118, -0.19825612424320377, -0.07679532176871919, -0.005774939588660706, 0.4073800974727018], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [29.319232940673828, 22.90365219116211, 18.219179153442383, 16.823884963989258, 12.734053611755371]}, \"tinfo\": {\"Term\": [\"trump\", \"peopl\", \"time\", \"year\", \"like\", \"state\", \"think\", \"say\", \"know\", \"go\", \"govern\", \"right\", \"good\", \"money\", \"want\", \"comment\", \"need\", \"thing\", \"fact\", \"chang\", \"public\", \"live\", \"look\", \"come\", \"care\", \"work\", \"support\", \"presid\", \"read\", \"polit\", \"peopl\", \"think\", \"know\", \"right\", \"want\", \"thing\", \"countri\", \"vote\", \"leav\", \"person\", \"mean\", \"elect\", \"liber\", \"believ\", \"world\", \"issu\", \"american\", \"actual\", \"tell\", \"parti\", \"give\", \"nation\", \"differ\", \"reason\", \"agre\", \"stop\", \"mayb\", \"case\", \"power\", \"tri\", \"get\", \"canada\", \"time\", \"year\", \"go\", \"good\", \"look\", \"live\", \"canadian\", \"better\", \"great\", \"help\", \"long\", \"start\", \"thank\", \"famili\", \"place\", \"littl\", \"home\", \"best\", \"hope\", \"play\", \"away\", \"trudeau\", \"children\", \"wonder\", \"probabl\", \"ignor\", \"servic\", \"see\", \"market\", \"drive\", \"come\", \"like\", \"make\", \"need\", \"work\", \"take\", \"state\", \"govern\", \"money\", \"chang\", \"public\", \"care\", \"polit\", \"busi\", \"cost\", \"pay\", \"hous\", \"school\", \"citi\", \"build\", \"alaska\", \"wrong\", \"spend\", \"fund\", \"tax\", \"major\", \"health\", \"hard\", \"feder\", \"increas\", \"provid\", \"immigr\", \"compani\", \"educ\", \"incom\", \"price\", \"current\", \"need\", \"canada\", \"work\", \"trump\", \"say\", \"comment\", \"fact\", \"presid\", \"read\", \"link\", \"articl\", \"post\", \"sure\", \"call\", \"white\", \"obama\", \"democrat\", \"republican\", \"news\", \"write\", \"stori\", \"report\", \"word\", \"matter\", \"continu\", \"america\", \"conserv\", \"opinion\", \"stand\", \"inform\", \"hillari\", \"correct\", \"head\", \"mind\", \"support\", \"point\", \"lose\", \"like\", \"life\", \"million\", \"question\", \"women\", \"church\", \"line\", \"pass\", \"job\", \"truth\", \"exact\", \"choos\", \"ask\", \"member\", \"senat\", \"sens\", \"answer\", \"cathol\", \"societi\", \"week\", \"accept\", \"meet\", \"experi\", \"fight\", \"suggest\", \"road\", \"self\", \"common\", \"legisl\", \"sign\", \"natur\"], \"Freq\": [24865.0, 31515.0, 20109.0, 19703.0, 29209.0, 15087.0, 20157.0, 13823.0, 19211.0, 14912.0, 12738.0, 17361.0, 14173.0, 10737.0, 14810.0, 9043.0, 16808.0, 11919.0, 8121.0, 8498.0, 8158.0, 9408.0, 9400.0, 12523.0, 7931.0, 14379.0, 9304.0, 7323.0, 7296.0, 7551.0, 31515.4921875, 20157.34765625, 19211.515625, 17361.51953125, 14810.1220703125, 11919.6083984375, 10174.55859375, 9968.7021484375, 8673.1298828125, 8524.455078125, 7976.1884765625, 7794.99267578125, 7730.8291015625, 7665.27490234375, 7700.3310546875, 7444.8896484375, 7321.96728515625, 7361.0517578125, 7149.26904296875, 6710.11376953125, 6746.33056640625, 6596.0732421875, 6500.01220703125, 6387.30517578125, 5596.935546875, 5441.10791015625, 5428.70458984375, 5041.23193359375, 4999.19091796875, 4882.720703125, 5487.84765625, 5529.36572265625, 20109.544921875, 19703.220703125, 14911.9951171875, 14173.5546875, 9400.349609375, 9408.43359375, 7309.4892578125, 7063.697265625, 6223.5302734375, 6075.470703125, 6035.0205078125, 5837.02734375, 5645.3251953125, 5448.6318359375, 5221.68701171875, 4935.2890625, 4909.00390625, 4746.7763671875, 4555.650390625, 4236.5791015625, 4063.91796875, 3981.02978515625, 3826.04345703125, 3769.803955078125, 3662.916015625, 3653.706787109375, 3615.29736328125, 3447.98583984375, 3366.001220703125, 3269.564453125, 10818.4501953125, 19861.767578125, 6527.13525390625, 12305.3623046875, 10643.5087890625, 6105.02001953125, 15087.4248046875, 12738.0361328125, 10737.017578125, 8497.91015625, 8158.1259765625, 7931.60595703125, 7551.4033203125, 6255.06103515625, 6094.6806640625, 5912.09130859375, 5757.47412109375, 5507.0126953125, 5022.9150390625, 4919.19287109375, 4882.61474609375, 4902.9140625, 4826.64697265625, 4723.4658203125, 4742.18359375, 4552.361328125, 4273.2587890625, 4217.029296875, 4146.7451171875, 3903.379150390625, 3878.901123046875, 3771.852294921875, 3700.06982421875, 3695.85595703125, 3594.193603515625, 3569.054931640625, 3608.9638671875, 4502.9970703125, 3867.490234375, 3735.60302734375, 24864.9765625, 13823.751953125, 9043.1767578125, 8121.22607421875, 7323.404296875, 7296.634765625, 7119.32275390625, 6302.13720703125, 6143.6845703125, 6136.5478515625, 5543.1015625, 5383.98388671875, 5384.51904296875, 5166.416015625, 5182.29736328125, 4937.63720703125, 4848.67138671875, 4423.38720703125, 4233.43115234375, 4188.8095703125, 4178.67919921875, 4196.2900390625, 3909.091064453125, 3720.812744140625, 3662.20263671875, 3639.970703125, 3378.86279296875, 3123.73095703125, 3121.202392578125, 3012.822021484375, 3031.96826171875, 8149.39453125, 5869.44482421875, 4149.7998046875, 9067.2255859375, 5721.21435546875, 5364.212890625, 5162.50830078125, 4538.509765625, 4194.26806640625, 3473.544921875, 3236.413818359375, 3191.6015625, 3123.195068359375, 2898.20947265625, 2808.568359375, 2700.35400390625, 2645.09619140625, 2651.852294921875, 2641.298095703125, 2606.70654296875, 2559.219970703125, 2558.2490234375, 2553.54443359375, 2508.042236328125, 2495.436279296875, 2459.37451171875, 2452.54296875, 2443.53466796875, 2397.357177734375, 2362.90673828125, 2304.642333984375, 2320.22119140625, 2309.180908203125, 2285.0205078125], \"Total\": [24865.0, 31515.0, 20109.0, 19703.0, 29209.0, 15087.0, 20157.0, 13823.0, 19211.0, 14912.0, 12738.0, 17361.0, 14173.0, 10737.0, 14810.0, 9043.0, 16808.0, 11919.0, 8121.0, 8498.0, 8158.0, 9408.0, 9400.0, 12523.0, 7931.0, 14379.0, 9304.0, 7323.0, 7296.0, 7551.0, 31515.58203125, 20157.4375, 19211.60546875, 17361.609375, 14810.212890625, 11919.69921875, 10174.6484375, 9968.7919921875, 8673.220703125, 8524.5458984375, 7976.27880859375, 7795.0830078125, 7730.91943359375, 7665.365234375, 7700.421875, 7444.97998046875, 7322.0576171875, 7361.142578125, 7149.35986328125, 6710.2041015625, 6746.42138671875, 6596.16357421875, 6500.10302734375, 6387.39599609375, 5597.0263671875, 5441.19873046875, 5428.79541015625, 5041.32275390625, 4999.28173828125, 4882.8115234375, 6571.97412109375, 9396.923828125, 20109.634765625, 19703.310546875, 14912.0859375, 14173.6455078125, 9400.4404296875, 9408.5244140625, 7309.580078125, 7063.7880859375, 6223.62109375, 6075.5615234375, 6035.111328125, 5837.1181640625, 5645.416015625, 5448.72265625, 5221.77783203125, 4935.3798828125, 4909.09423828125, 4746.8671875, 4555.7412109375, 4236.669921875, 4064.008544921875, 3981.120361328125, 3826.13427734375, 3769.89453125, 3663.006591796875, 3653.798095703125, 3615.387939453125, 3448.076171875, 3366.091796875, 3269.654541015625, 12523.814453125, 29209.3515625, 7587.47998046875, 16808.427734375, 14379.1806640625, 7881.3212890625, 15087.5146484375, 12738.1259765625, 10737.107421875, 8498.001953125, 8158.216796875, 7931.69677734375, 7551.49560546875, 6255.15185546875, 6094.7705078125, 5912.18212890625, 5757.56494140625, 5507.103515625, 5023.005859375, 4919.28369140625, 4882.70556640625, 4903.00634765625, 4826.73779296875, 4723.5556640625, 4742.2734375, 4552.4521484375, 4273.349609375, 4217.12060546875, 4146.8359375, 3903.46923828125, 3878.991943359375, 3771.943115234375, 3700.159912109375, 3695.9462890625, 3594.283203125, 3569.14501953125, 3609.054931640625, 16808.427734375, 9396.923828125, 14379.1806640625, 24865.06640625, 13823.8427734375, 9043.2666015625, 8121.31689453125, 7323.49462890625, 7296.7255859375, 7119.41357421875, 6302.22802734375, 6143.77490234375, 6136.63916015625, 5543.1923828125, 5384.07421875, 5384.609375, 5166.50634765625, 5182.3876953125, 4937.7275390625, 4848.76220703125, 4423.4775390625, 4233.52197265625, 4188.89990234375, 4178.77001953125, 4196.38134765625, 3909.181640625, 3720.9033203125, 3662.293212890625, 3640.0615234375, 3378.95361328125, 3123.82080078125, 3121.293701171875, 3012.912841796875, 3032.059326171875, 9304.134765625, 8057.18505859375, 4946.10498046875, 29209.3515625, 5721.30419921875, 5364.3037109375, 5162.5986328125, 4538.59912109375, 4194.35693359375, 3473.635498046875, 3236.50439453125, 3191.692138671875, 3123.285400390625, 2898.300048828125, 2808.65869140625, 2700.444580078125, 2645.1865234375, 2651.94287109375, 2641.388427734375, 2606.79638671875, 2559.30908203125, 2558.3388671875, 2553.635009765625, 2508.13232421875, 2495.52685546875, 2459.464599609375, 2452.633544921875, 2443.625, 2397.447509765625, 2362.996826171875, 2304.732421875, 2320.31201171875, 2309.271728515625, 2285.110595703125], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.5641000270843506, -4.011000156402588, -4.059000015258789, -4.160299777984619, -4.319200038909912, -4.536399841308594, -4.694699764251709, -4.715099811553955, -4.854300022125244, -4.871600151062012, -4.9380998611450195, -4.961100101470947, -4.969299793243408, -4.977799892425537, -4.973299980163574, -5.006999969482422, -5.02370023727417, -5.0183000564575195, -5.047500133514404, -5.110899925231934, -5.105500221252441, -5.1280999183654785, -5.1427001953125, -5.160200119018555, -5.292300224304199, -5.3206000328063965, -5.322800159454346, -5.396900177001953, -5.405300140380859, -5.428800106048584, -5.311999797821045, -5.304500102996826, -3.766400098800659, -3.786799907684326, -4.065400123596191, -4.116199970245361, -4.526800155639648, -4.526000022888184, -4.77839994430542, -4.812600135803223, -4.939300060272217, -4.9633002281188965, -4.96999979019165, -5.003399848937988, -5.036799907684326, -5.072199821472168, -5.114799976348877, -5.171199798583984, -5.176499843597412, -5.210100173950195, -5.251200199127197, -5.323800086975098, -5.3653998374938965, -5.386099815368652, -5.42579984664917, -5.4405999183654785, -5.469299793243408, -5.47189998626709, -5.482399940490723, -5.529799938201904, -5.553899765014648, -5.582900047302246, -4.386300086975098, -3.7788000106811523, -4.891600131988525, -4.257599830627441, -4.402599811553955, -4.958499908447266, -3.824899911880493, -3.9941999912261963, -4.16510009765625, -4.39900016784668, -4.439799785614014, -4.467899799346924, -4.517000198364258, -4.705399990081787, -4.731400012969971, -4.7617998123168945, -4.788300037384033, -4.832799911499023, -4.924799919128418, -4.9456000328063965, -4.953100204467773, -4.94890022277832, -4.964600086212158, -4.986199855804443, -4.9822998046875, -5.023099899291992, -5.086400032043457, -5.099599838256836, -5.116399765014648, -5.1768999099731445, -5.183199882507324, -5.21120023727417, -5.230400085449219, -5.231599807739258, -5.259500026702881, -5.266499996185303, -5.25540018081665, -5.033999919891357, -5.186200141906738, -5.220900058746338, -3.2455999851226807, -3.83270001411438, -4.2571001052856445, -4.36460018157959, -4.4679999351501465, -4.471700191497803, -4.496300220489502, -4.618199825286865, -4.643700122833252, -4.644800186157227, -4.746500015258789, -4.775700092315674, -4.775599956512451, -4.81689977645874, -4.813799858093262, -4.862199783325195, -4.88040018081665, -4.9721999168396, -5.01609992980957, -5.026700019836426, -5.029099941253662, -5.024899959564209, -5.095799922943115, -5.145199775695801, -5.160999774932861, -5.167099952697754, -5.241600036621094, -5.320099830627441, -5.320899963378906, -5.356200218200684, -5.349899768829346, -4.361199855804443, -4.689300060272217, -5.035999774932861, -4.25439977645874, -4.436399936676025, -4.500800132751465, -4.5391998291015625, -4.668000221252441, -4.7469000816345215, -4.935400009155273, -5.006100177764893, -5.020100116729736, -5.0416998863220215, -5.116499900817871, -5.147900104522705, -5.18720006942749, -5.207900047302246, -5.2052998542785645, -5.2093000411987305, -5.222499847412109, -5.240900039672852, -5.241300106048584, -5.243100166320801, -5.261099815368652, -5.26609992980957, -5.280700206756592, -5.2835001945495605, -5.287099838256836, -5.30620002746582, -5.320700168609619, -5.345699787139893, -5.338900089263916, -5.343699932098389, -5.3541998863220215], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.2268999814987183, 1.0465999841690063, 0.6966000199317932, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4738999605178833, 1.4737999439239502, 1.4737999439239502, 1.4737999439239502, 1.4737999439239502, 1.4737999439239502, 1.4737999439239502, 1.4737999439239502, 1.3274999856948853, 1.0881999731063843, 1.3233000040054321, 1.1619999408721924, 1.1729999780654907, 1.218500018119812, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 1.7027000188827515, 0.3856000006198883, 0.8148999810218811, 0.3547999858856201, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7824000120162964, 1.7822999954223633, 1.7822999954223633, 1.7822999954223633, 1.7822999954223633, 1.7822999954223633, 1.7822999954223633, 1.7822999954223633, 1.7822999954223633, 1.7822999954223633, 1.7822999954223633, 1.7822999954223633, 1.7822999954223633, 1.7822999954223633, 1.649899959564209, 1.4656000137329102, 1.6067999601364136, 0.612500011920929, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494, 2.0608999729156494]}, \"token.table\": {\"Topic\": [5, 1, 1, 3, 4, 1, 5, 4, 5, 2, 1, 2, 2, 3, 3, 4, 1, 3, 2, 3, 1, 5, 3, 2, 5, 5, 3, 1, 2, 4, 5, 3, 4, 4, 4, 3, 1, 3, 4, 1, 2, 3, 1, 5, 5, 4, 2, 3, 5, 3, 1, 3, 1, 2, 2, 3, 2, 3, 4, 3, 2, 4, 2, 2, 3, 2, 3, 3, 3, 4, 1, 5, 1, 1, 5, 1, 5, 1, 2, 4, 5, 4, 2, 2, 2, 2, 3, 4, 3, 2, 4, 2, 4, 1, 1, 5, 5, 5, 4, 3, 1, 5, 2, 3, 4, 4, 4, 1, 5, 3, 1, 1, 2, 2, 2, 4, 3, 4, 1, 4, 3, 2, 3, 3, 5, 4, 1, 4, 4, 1, 5, 4, 3, 2, 5, 5, 5, 2, 5, 5, 3, 4, 2, 3, 1, 4, 5, 3, 4, 4, 1, 2, 3, 1, 2, 1, 1, 2, 1, 2, 4, 5, 1, 1, 5, 4, 5, 2, 4, 2, 3, 1, 4, 3, 2], \"Freq\": [0.9999472498893738, 0.999980628490448, 0.9999952912330627, 1.0000603199005127, 0.9999535083770752, 0.9999921321868896, 1.0000780820846558, 0.9999638199806213, 0.9998353719711304, 0.9999979138374329, 0.9999523758888245, 1.0000280141830444, 1.0000300407409668, 0.9999423027038574, 0.9999757409095764, 0.9999653100967407, 0.5883840322494507, 0.4115176498889923, 0.999920666217804, 1.0000382661819458, 0.9999359846115112, 0.9998792409896851, 0.9999997615814209, 0.9999648928642273, 1.0001214742660522, 0.9999148845672607, 0.9999988079071045, 0.1361406296491623, 0.8637943267822266, 0.9999704957008362, 1.0001161098480225, 0.9999567866325378, 1.000025987625122, 0.9999091029167175, 0.9999058842658997, 1.000037670135498, 1.0000345706939697, 0.9999848008155823, 0.9999020099639893, 0.9999841451644897, 1.000105619430542, 1.0000145435333252, 0.9999893307685852, 0.9998964667320251, 0.9998111128807068, 0.9999609589576721, 1.0000509023666382, 1.0000395774841309, 1.0001493692398071, 0.9998823404312134, 0.8350611329078674, 0.16494283080101013, 0.9999375343322754, 0.9999942183494568, 1.0000250339508057, 0.9999901056289673, 1.0000609159469604, 0.9999713897705078, 1.0000289678573608, 0.9999181628227234, 0.9999075531959534, 1.000057339668274, 0.9999808073043823, 1.0000568628311157, 0.9999018907546997, 1.0000553131103516, 1.000015139579773, 0.9999212026596069, 0.999879777431488, 1.0000137090682983, 1.0000027418136597, 1.0000964403152466, 1.0000205039978027, 0.9999745488166809, 0.9998655319213867, 1.000010371208191, 0.9999468326568604, 0.009585971012711525, 0.6799877285957336, 0.31041428446769714, 1.0001049041748047, 0.999941885471344, 0.999923050403595, 0.999944269657135, 0.9999815821647644, 0.9999531507492065, 0.160934716463089, 0.8390440344810486, 0.9999006986618042, 0.8602328896522522, 0.13970382511615753, 0.9999727010726929, 1.0000550746917725, 1.000037670135498, 0.9999650716781616, 0.9997888803482056, 0.9999294877052307, 0.9999433755874634, 0.9999804496765137, 0.9999899864196777, 0.9999752044677734, 0.9999516010284424, 0.7320732474327087, 0.26790133118629456, 1.000055193901062, 1.0000725984573364, 0.9999199509620667, 0.9999696016311646, 0.9998441338539124, 0.9999691843986511, 0.9999815225601196, 0.9999359846115112, 1.0000425577163696, 1.0000779628753662, 0.27155885100364685, 0.7284181714057922, 0.9999343752861023, 1.000036597251892, 0.9999436736106873, 0.9999324679374695, 0.9999593496322632, 0.9999982118606567, 1.0000020265579224, 0.9999734163284302, 1.000077724456787, 1.0000375509262085, 0.9999380111694336, 0.9998766779899597, 0.9999251961708069, 1.000022530555725, 0.9998133182525635, 1.0000113248825073, 0.9999812245368958, 0.9999778866767883, 1.000001311302185, 1.0000215768814087, 0.9998529553413391, 0.9998927116394043, 0.9998823404312134, 0.9998675584793091, 1.0000543594360352, 0.9999830722808838, 0.9999797344207764, 0.9999659061431885, 0.9999634623527527, 0.9998920559883118, 1.0001534223556519, 0.12413835525512695, 0.8758471608161926, 1.0000587701797485, 0.22534292936325073, 0.7746163010597229, 0.9999423623085022, 0.9999496936798096, 0.9999263286590576, 1.0000252723693848, 0.9999783039093018, 1.0000181198120117, 1.0000386238098145, 0.9999697804450989, 0.9999973177909851, 0.9999086260795593, 1.0000208616256714, 0.9999856352806091, 1.0001429319381714, 0.9999862313270569, 1.0000883340835571, 1.0000280141830444, 1.0000238418579102, 0.7402368783950806, 0.2598201036453247, 0.9999452233314514, 1.0000489950180054, 0.9999986886978149, 0.9999842643737793], \"Term\": [\"accept\", \"actual\", \"agre\", \"alaska\", \"america\", \"american\", \"answer\", \"articl\", \"ask\", \"away\", \"believ\", \"best\", \"better\", \"build\", \"busi\", \"call\", \"canada\", \"canada\", \"canadian\", \"care\", \"case\", \"cathol\", \"chang\", \"children\", \"choos\", \"church\", \"citi\", \"come\", \"come\", \"comment\", \"common\", \"compani\", \"conserv\", \"continu\", \"correct\", \"cost\", \"countri\", \"current\", \"democrat\", \"differ\", \"drive\", \"educ\", \"elect\", \"exact\", \"experi\", \"fact\", \"famili\", \"feder\", \"fight\", \"fund\", \"get\", \"get\", \"give\", \"go\", \"good\", \"govern\", \"great\", \"hard\", \"head\", \"health\", \"help\", \"hillari\", \"home\", \"hope\", \"hous\", \"ignor\", \"immigr\", \"incom\", \"increas\", \"inform\", \"issu\", \"job\", \"know\", \"leav\", \"legisl\", \"liber\", \"life\", \"like\", \"like\", \"like\", \"line\", \"link\", \"littl\", \"live\", \"long\", \"look\", \"lose\", \"lose\", \"major\", \"make\", \"make\", \"market\", \"matter\", \"mayb\", \"mean\", \"meet\", \"member\", \"million\", \"mind\", \"money\", \"nation\", \"natur\", \"need\", \"need\", \"news\", \"obama\", \"opinion\", \"parti\", \"pass\", \"pay\", \"peopl\", \"person\", \"place\", \"play\", \"point\", \"point\", \"polit\", \"post\", \"power\", \"presid\", \"price\", \"probabl\", \"provid\", \"public\", \"question\", \"read\", \"reason\", \"report\", \"republican\", \"right\", \"road\", \"say\", \"school\", \"see\", \"self\", \"senat\", \"sens\", \"servic\", \"sign\", \"societi\", \"spend\", \"stand\", \"start\", \"state\", \"stop\", \"stori\", \"suggest\", \"support\", \"support\", \"sure\", \"take\", \"take\", \"tax\", \"tell\", \"thank\", \"thing\", \"think\", \"time\", \"tri\", \"trudeau\", \"trump\", \"truth\", \"vote\", \"want\", \"week\", \"white\", \"women\", \"wonder\", \"word\", \"work\", \"work\", \"world\", \"write\", \"wrong\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 5, 2, 3, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1381397650490819287457923898\", ldavis_el1381397650490819287457923898_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1381397650490819287457923898\", ldavis_el1381397650490819287457923898_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1381397650490819287457923898\", ldavis_el1381397650490819287457923898_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "3      0.316418 -0.126554       1        1  29.319233\n",
              "4     -0.116165 -0.198256       2        1  22.903652\n",
              "1      0.076988 -0.076795       3        1  18.219179\n",
              "2     -0.328856 -0.005775       4        1  16.823885\n",
              "0      0.051615  0.407380       5        1  12.734054, topic_info=        Term          Freq         Total Category  logprob  loglift\n",
              "36     trump  24865.000000  24865.000000  Default  30.0000  30.0000\n",
              "48     peopl  31515.000000  31515.000000  Default  29.0000  29.0000\n",
              "325     time  20109.000000  20109.000000  Default  28.0000  28.0000\n",
              "225     year  19703.000000  19703.000000  Default  27.0000  27.0000\n",
              "101     like  29209.000000  29209.000000  Default  26.0000  26.0000\n",
              "...      ...           ...           ...      ...      ...      ...\n",
              "526     self   2362.906738   2362.996826   Topic5  -5.3207   2.0609\n",
              "2715  common   2304.642334   2304.732422   Topic5  -5.3457   2.0609\n",
              "146   legisl   2320.221191   2320.312012   Topic5  -5.3389   2.0609\n",
              "1805    sign   2309.180908   2309.271729   Topic5  -5.3437   2.0609\n",
              "1247   natur   2285.020508   2285.110596   Topic5  -5.3542   2.0609\n",
              "\n",
              "[197 rows x 6 columns], token_table=      Topic      Freq     Term\n",
              "term                          \n",
              "555       5  0.999947   accept\n",
              "396       1  0.999981   actual\n",
              "1313      1  0.999995     agre\n",
              "425       3  1.000060   alaska\n",
              "27        4  0.999954  america\n",
              "...     ...       ...      ...\n",
              "353       3  0.259820     work\n",
              "394       1  0.999945    world\n",
              "395       4  1.000049    write\n",
              "433       3  0.999999    wrong\n",
              "225       2  0.999984     year\n",
              "\n",
              "[175 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 5, 2, 3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdnphAaW4mwM",
        "colab_type": "text"
      },
      "source": [
        "### Test Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5qruRID4quB",
        "colab_type": "code",
        "outputId": "562d5ba6-6613-4168-8510-29bda4f0dd04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%%time\n",
        "data11 = X_te.clean_text.values.tolist()\n",
        "processed_docs11 = []\n",
        "for doc in data11:\n",
        "    processed_docs11.append(preprocess(doc))\n",
        "\n",
        "print(processed_docs11[:1])\n",
        "corpus11= [dictionary.doc2bow(text) for text in processed_docs11]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['breath', 'fresh', 'embrac', 'common', 'sens', 'valu', 'instead', 'leadership', 'canada', 'clear', 'differ', 'page', 'read', 'differ', 'book']]\n",
            "CPU times: user 1min 24s, sys: 393 ms, total: 1min 25s\n",
            "Wall time: 1min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY6zn0qa1xRY",
        "colab_type": "text"
      },
      "source": [
        "# Actual test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkp3VSCy11_z",
        "colab_type": "code",
        "outputId": "6a04c423-6837-41c4-a883-6948991282c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#will use for submission\n",
        "%%time\n",
        "data_test = test.clean_text.values.tolist()\n",
        "processed_docs_test = []\n",
        "for doc in data_test:\n",
        "    processed_docs_test.append(preprocess(doc))\n",
        "\n",
        "print(processed_docs_test[:1])\n",
        "corpus_test= [dictionary.doc2bow(text) for text in processed_docs_test]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['integr', 'mean', 'debt', 'appli', 'presid', 'trump']]\n",
            "CPU times: user 45.9 s, sys: 238 ms, total: 46.2 s\n",
            "Wall time: 46.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qjyi5epG6B_",
        "colab_type": "text"
      },
      "source": [
        "# Converting Topics to Feature Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP02CqVIKC-k",
        "colab_type": "code",
        "outputId": "0011662f-5125-4b65-a171-a96575bc79ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# For train vectors\n",
        "train_vecs = []\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    top_train_topics = lda_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
        "    topic_train_vec = [top_train_topics[i][1] for i in range(5)]\n",
        "    train_vecs.append(topic_train_vec)\n",
        "# Printing top five train vectors \n",
        "train_vecs[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.2572527, 0.116501085, 0.15880889, 0.23540507, 0.23203227],\n",
              " [0.1085511, 0.12808271, 0.23760512, 0.205904, 0.31985703],\n",
              " [0.10038725, 0.13197713, 0.24514905, 0.28512138, 0.23736522],\n",
              " [0.100387305, 0.13197719, 0.24514884, 0.23232232, 0.29016432],\n",
              " [0.09079904, 0.11937169, 0.22173429, 0.21013263, 0.35796234]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8YF6-NyEiVm",
        "colab_type": "code",
        "outputId": "6fa559ab-a063-48bb-f610-39daa21ce72b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# For cv vectors\n",
        "cv_vecs = []\n",
        "for i in range(len(X_cv)):\n",
        "    top_cv_topics = lda_model.get_document_topics(corpus1[i], minimum_probability=0.0)\n",
        "    topic_cv_vec = [top_cv_topics[i][1] for i in range(5)]\n",
        "    cv_vecs.append(topic_cv_vec)\n",
        "# Printing top five test vectors\n",
        "cv_vecs[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.09080016, 0.16712835, 0.17397994, 0.30563962, 0.2624519],\n",
              " [0.23157655, 0.07987076, 0.23264326, 0.25131276, 0.20459664],\n",
              " [0.132223, 0.1595133, 0.16605367, 0.33729813, 0.2049119],\n",
              " [0.06035246, 0.14152181, 0.17819482, 0.3855083, 0.23442256],\n",
              " [0.1206431, 0.13538024, 0.18808436, 0.24763924, 0.30825308]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF2X9FUPEElO",
        "colab_type": "code",
        "outputId": "8b7fc643-3717-4318-a19d-783843a37745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# For test vectors\n",
        "te_vecs = []\n",
        "\n",
        "for i in range(len(X_te)):\n",
        "    top_te_topics = lda_model.get_document_topics(corpus11[i], minimum_probability=0.0)\n",
        "    topic_te_vec = [top_te_topics[i][1] for i in range(5)]\n",
        "    te_vecs.append(topic_te_vec)\n",
        "# Printing top five test vectors\n",
        "te_vecs[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.1436283, 0.28519964, 0.16165379, 0.14947933, 0.26003894],\n",
              " [0.075519, 0.11585588, 0.19756171, 0.23977299, 0.37129042],\n",
              " [0.19178723, 0.16131727, 0.134504, 0.26750937, 0.24488218],\n",
              " [0.16126405, 0.080642395, 0.21566236, 0.2366619, 0.30576932],\n",
              " [0.070576765, 0.2041459, 0.17327477, 0.2737662, 0.27823636]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOu524HX2k39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For actual test vectors\n",
        "test_vecs = []\n",
        "\n",
        "for i in range(len(test)):\n",
        "    top_test_topics = lda_model.get_document_topics(corpus_test[i], minimum_probability=0.0)\n",
        "    topic_test_vec = [top_test_topics[i][1] for i in range(5)]\n",
        "    test_vecs.append(topic_test_vec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D0NtqkNbRGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the new df with 5 topics \n",
        "train_features = pd.DataFrame(train_vecs,columns=['Topic-1','Topic-2','Topic-3','Topic-4','Topic-5'])\n",
        "cv_features = pd.DataFrame(cv_vecs,columns=['Topic-1','Topic-2','Topic-3','Topic-4','Topic-5'])\n",
        "te_features = pd.DataFrame(te_vecs,columns=['Topic-1','Topic-2','Topic-3','Topic-4','Topic-5'])\n",
        "test_features = pd.DataFrame(test_vecs,columns=['Topic-1','Topic-2','Topic-3','Topic-4','Topic-5'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-3TqMAhEXog",
        "colab_type": "text"
      },
      "source": [
        "# Count number of positive and negative words in each comment\n",
        "- https://gist.github.com/mkulakowski2/4289441\n",
        "- https://gist.github.com/mkulakowski2/4289437"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJD5d8mwGk-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I have created 2 files one for  positive words taken from https://gist.github.com/mkulakowski2/4289437 ,another for negative words taken from https://gist.github.com/mkulakowski2/4289441\n",
        "\n",
        "#load pos,neg words\n",
        "pos_path='/content/drive/My Drive/jigsaw/pos.txt'\n",
        "neg_path='/content/drive/My Drive/jigsaw/neg.txt'\n",
        "\n",
        "def load_file(path):\n",
        "  fp=open(path,'r')\n",
        "  all_lines=fp.readlines()\n",
        "  words_list=[]\n",
        "  for line in all_lines:\n",
        "    words_list.append(line.strip())\n",
        "  fp.close()\n",
        "  return words_list\n",
        "\n",
        "pos_words=load_file(pos_path)\n",
        "neg_words=load_file(neg_path)\n",
        "\n",
        "#count  number of positive and negative words in each comment\n",
        "def pos_word_count(comment):\n",
        "  count=0\n",
        "  for word in comment.split():\n",
        "    if word in pos_words:\n",
        "      count=count+1\n",
        "  return count  \n",
        "\n",
        "def neg_word_count(comment):\n",
        "  count=0\n",
        "  for word in comment.split():\n",
        "    if word in neg_words:\n",
        "      count=count+1\n",
        "  return count  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVJ5OgJMEhwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pos_word_count \n",
        "count=[]\n",
        "for i in X_train['clean_text'].values:\n",
        "  count.append(pos_word_count(str(i)))\n",
        "train_features['pos_word_count']=count\n",
        "\n",
        "count=[]\n",
        "for i in X_cv['clean_text'].values:\n",
        "  count.append(pos_word_count(str(i)))\n",
        "cv_features['pos_word_count']=count\n",
        "\n",
        "count=[]\n",
        "for i in X_te['clean_text'].values:\n",
        "  count.append(pos_word_count(str(i)))\n",
        "te_features['pos_word_count']=count\n",
        "\n",
        "count=[]\n",
        "for i in test['clean_text'].values:\n",
        "  count.append(pos_word_count(str(i)))\n",
        "test_features['pos_word_count']=count\n",
        "\n",
        "# neg_word_count\n",
        "count=[]\n",
        "for i in X_train['clean_text'].values:\n",
        "  count.append(neg_word_count(str(i)))\n",
        "train_features['neg_word_count']=count\n",
        "\n",
        "count=[]\n",
        "for i in X_cv['clean_text'].values:\n",
        "  count.append(neg_word_count(str(i)))\n",
        "cv_features['neg_word_count']=count\n",
        "\n",
        "count=[]\n",
        "for i in X_te['clean_text'].values:\n",
        "  count.append(neg_word_count(str(i)))\n",
        "te_features['neg_word_count']=count\n",
        "\n",
        "count=[]\n",
        "for i in test['clean_text'].values:\n",
        "  count.append(pos_word_count(str(i)))\n",
        "test_features['neg_word_count']=count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hWqaSdQlEav",
        "colab_type": "text"
      },
      "source": [
        "# Find the  sentiment of each comment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91gyJtqBFq2s",
        "colab_type": "code",
        "outputId": "9bfd31c5-4fd1-4df7-9b59-c691aeacb0d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#https://www.pluralsight.com/guides/natural-language-processing-extracting-sentiment-from-text-data\n",
        "%%time\n",
        "sentiment_count=[]\n",
        "for i in X_train['clean_text'].values:\n",
        "  sentiment_count.append(TextBlob(i).sentiment[0])\n",
        "train_features['sentiment']=sentiment_count\n",
        "\n",
        "sentiment_count=[]\n",
        "for i in X_cv['clean_text'].values:\n",
        "  sentiment_count.append(TextBlob(i).sentiment[0])\n",
        "cv_features['sentiment']=sentiment_count\n",
        "\n",
        "sentiment_count=[]\n",
        "for i in X_te['clean_text'].values:\n",
        "  sentiment_count.append(TextBlob(i).sentiment[0])\n",
        "te_features['sentiment']=sentiment_count\n",
        "\n",
        "sentiment_count=[]\n",
        "for i in test['clean_text'].values:\n",
        "  sentiment_count.append(TextBlob(i).sentiment[0])\n",
        "test_features['sentiment']=sentiment_count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 19min 6s, sys: 2.87 s, total: 19min 9s\n",
            "Wall time: 19min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfhMZ30Vl0-L",
        "colab_type": "text"
      },
      "source": [
        "# Features calculated during the EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaSakJZ5GAN0",
        "colab_type": "code",
        "outputId": "d774416d-0203-46fc-cf95-50b547ddc68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "from tqdm import tqdm\n",
        "#comment_word_count\n",
        "count=[]\n",
        "for i in tqdm(X_train['clean_text'].values):\n",
        "  count.append(len(i.split()))\n",
        "train_features['comment_word_count']=count\n",
        "\n",
        "count=[]\n",
        "for i in tqdm(X_cv['clean_text'].values):\n",
        "  count.append(len(i.split()))\n",
        "cv_features['comment_word_count']=count\n",
        "\n",
        "count=[]\n",
        "for i in tqdm(X_te['clean_text'].values):\n",
        "  count.append(len(i.split()))\n",
        "te_features['comment_word_count']=count\n",
        "\n",
        "count=[]\n",
        "for i in tqdm(test['clean_text'].values):\n",
        "  count.append(len(i.split()))\n",
        "test_features['comment_word_count']=count\n",
        "\n",
        "#comment_char_count\n",
        "\n",
        "count=[]\n",
        "for i in tqdm(X_train['clean_text'].values):\n",
        "  count.append(len(i))\n",
        "train_features['comment_char_count']=count\n",
        "\n",
        "count=[]\n",
        "for i in tqdm(X_cv['clean_text'].values):\n",
        "  count.append(len(i))\n",
        "cv_features['comment_char_count']=count\n",
        "\n",
        "count=[]\n",
        "for i in tqdm(X_te['clean_text'].values):\n",
        "  count.append(len(i))\n",
        "te_features['comment_char_count']=count\n",
        "\n",
        "count=[]\n",
        "for i in tqdm(test['clean_text'].values):\n",
        "  count.append(len(i))\n",
        "test_features['comment_char_count']=count"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1461947/1461947 [00:03<00:00, 379699.89it/s]\n",
            "100%|██████████| 162439/162439 [00:00<00:00, 351337.65it/s]\n",
            "100%|██████████| 180488/180488 [00:00<00:00, 354918.62it/s]\n",
            "100%|██████████| 97320/97320 [00:00<00:00, 390665.21it/s]\n",
            "100%|██████████| 1461947/1461947 [00:00<00:00, 1607047.00it/s]\n",
            "100%|██████████| 162439/162439 [00:00<00:00, 1488215.71it/s]\n",
            "100%|██████████| 180488/180488 [00:00<00:00, 1514697.43it/s]\n",
            "100%|██████████| 97320/97320 [00:00<00:00, 1503715.79it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrie-AqPMgVm",
        "colab_type": "code",
        "outputId": "c2c28f23-4749-4b58-c83e-fac4b4def241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "test_features"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic-1</th>\n",
              "      <th>Topic-2</th>\n",
              "      <th>Topic-3</th>\n",
              "      <th>Topic-4</th>\n",
              "      <th>Topic-5</th>\n",
              "      <th>pos_word_count</th>\n",
              "      <th>neg_word_count</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>comment_word_count</th>\n",
              "      <th>comment_char_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.149603</td>\n",
              "      <td>0.176198</td>\n",
              "      <td>0.133320</td>\n",
              "      <td>0.316583</td>\n",
              "      <td>0.224297</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.195654</td>\n",
              "      <td>0.175510</td>\n",
              "      <td>0.132552</td>\n",
              "      <td>0.220671</td>\n",
              "      <td>0.275613</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.105486</td>\n",
              "      <td>0.196813</td>\n",
              "      <td>0.275211</td>\n",
              "      <td>0.191042</td>\n",
              "      <td>0.231447</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>19</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.183384</td>\n",
              "      <td>0.153363</td>\n",
              "      <td>0.218330</td>\n",
              "      <td>0.211242</td>\n",
              "      <td>0.233680</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.305556</td>\n",
              "      <td>96</td>\n",
              "      <td>638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.178390</td>\n",
              "      <td>0.231265</td>\n",
              "      <td>0.128876</td>\n",
              "      <td>0.252196</td>\n",
              "      <td>0.209274</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.108571</td>\n",
              "      <td>30</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97315</th>\n",
              "      <td>0.095354</td>\n",
              "      <td>0.141435</td>\n",
              "      <td>0.132553</td>\n",
              "      <td>0.304900</td>\n",
              "      <td>0.325758</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97316</th>\n",
              "      <td>0.136550</td>\n",
              "      <td>0.126796</td>\n",
              "      <td>0.222251</td>\n",
              "      <td>0.236765</td>\n",
              "      <td>0.277638</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0.283333</td>\n",
              "      <td>30</td>\n",
              "      <td>186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97317</th>\n",
              "      <td>0.212566</td>\n",
              "      <td>0.177888</td>\n",
              "      <td>0.139512</td>\n",
              "      <td>0.281822</td>\n",
              "      <td>0.188212</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>7</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97318</th>\n",
              "      <td>0.189127</td>\n",
              "      <td>0.242099</td>\n",
              "      <td>0.098241</td>\n",
              "      <td>0.195365</td>\n",
              "      <td>0.275169</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.104762</td>\n",
              "      <td>19</td>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97319</th>\n",
              "      <td>0.232680</td>\n",
              "      <td>0.114726</td>\n",
              "      <td>0.201673</td>\n",
              "      <td>0.277116</td>\n",
              "      <td>0.173805</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.061616</td>\n",
              "      <td>54</td>\n",
              "      <td>313</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>97320 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Topic-1   Topic-2  ...  comment_word_count  comment_char_count\n",
              "0      0.149603  0.176198  ...                   8                  52\n",
              "1      0.195654  0.175510  ...                   7                  55\n",
              "2      0.105486  0.196813  ...                  19                 120\n",
              "3      0.183384  0.153363  ...                  96                 638\n",
              "4      0.178390  0.231265  ...                  30                 202\n",
              "...         ...       ...  ...                 ...                 ...\n",
              "97315  0.095354  0.141435  ...                   8                  54\n",
              "97316  0.136550  0.126796  ...                  30                 186\n",
              "97317  0.212566  0.177888  ...                   7                  43\n",
              "97318  0.189127  0.242099  ...                  19                 120\n",
              "97319  0.232680  0.114726  ...                  54                 313\n",
              "\n",
              "[97320 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2q670hO2Vd5",
        "colab_type": "text"
      },
      "source": [
        "# Encoding Numerical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gT8fx8ILG5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numerical_train_1=train_features['Topic-1'].values.reshape(-1, 1)\n",
        "numerical_train_2=train_features['Topic-2'].values.reshape(-1, 1)\n",
        "numerical_train_3=train_features['Topic-3'].values.reshape(-1, 1)\n",
        "numerical_train_4=train_features['Topic-4'].values.reshape(-1, 1)\n",
        "numerical_train_5=train_features['Topic-5'].values.reshape(-1, 1)\n",
        "numerical_train_6=train_features['pos_word_count'].values.reshape(-1, 1)\n",
        "numerical_train_7=train_features['neg_word_count'].values.reshape(-1, 1)\n",
        "numerical_train_8=train_features['sentiment'].values.reshape(-1, 1)\n",
        "numerical_train_9=train_features['comment_word_count'].values.reshape(-1, 1)\n",
        "numerical_train_10=train_features['comment_char_count'].values.reshape(-1, 1)\n",
        "\n",
        "numerical_cv_1=cv_features['Topic-1'].values.reshape(-1, 1)\n",
        "numerical_cv_2=cv_features['Topic-2'].values.reshape(-1, 1)\n",
        "numerical_cv_3=cv_features['Topic-3'].values.reshape(-1, 1)\n",
        "numerical_cv_4=cv_features['Topic-4'].values.reshape(-1, 1)\n",
        "numerical_cv_5=cv_features['Topic-5'].values.reshape(-1, 1)\n",
        "numerical_cv_6=cv_features['pos_word_count'].values.reshape(-1, 1)\n",
        "numerical_cv_7=cv_features['neg_word_count'].values.reshape(-1, 1)\n",
        "numerical_cv_8=cv_features['sentiment'].values.reshape(-1, 1)\n",
        "numerical_cv_9=cv_features['comment_word_count'].values.reshape(-1, 1)\n",
        "numerical_cv_10=cv_features['comment_char_count'].values.reshape(-1, 1)\n",
        "\n",
        "numerical_te_1=te_features['Topic-1'].values.reshape(-1, 1)\n",
        "numerical_te_2=te_features['Topic-2'].values.reshape(-1, 1)\n",
        "numerical_te_3=te_features['Topic-3'].values.reshape(-1, 1)\n",
        "numerical_te_4=te_features['Topic-4'].values.reshape(-1, 1)\n",
        "numerical_te_5=te_features['Topic-5'].values.reshape(-1, 1)\n",
        "numerical_te_6=te_features['pos_word_count'].values.reshape(-1, 1)\n",
        "numerical_te_7=te_features['neg_word_count'].values.reshape(-1, 1)\n",
        "numerical_te_8=te_features['sentiment'].values.reshape(-1, 1)\n",
        "numerical_te_9=te_features['comment_word_count'].values.reshape(-1, 1)\n",
        "numerical_te_10=te_features['comment_char_count'].values.reshape(-1, 1)\n",
        "\n",
        "numerical_test_1=test_features['Topic-1'].values.reshape(-1, 1)\n",
        "numerical_test_2=test_features['Topic-2'].values.reshape(-1, 1)\n",
        "numerical_test_3=test_features['Topic-3'].values.reshape(-1, 1)\n",
        "numerical_test_4=test_features['Topic-4'].values.reshape(-1, 1)\n",
        "numerical_test_5=test_features['Topic-5'].values.reshape(-1, 1)\n",
        "numerical_test_6=test_features['pos_word_count'].values.reshape(-1, 1)\n",
        "numerical_test_7=test_features['neg_word_count'].values.reshape(-1, 1)\n",
        "numerical_test_8=test_features['sentiment'].values.reshape(-1, 1)\n",
        "numerical_test_9=test_features['comment_word_count'].values.reshape(-1, 1)\n",
        "numerical_test_10=test_features['comment_char_count'].values.reshape(-1, 1)\n",
        "\n",
        "\n",
        "num_tr=np.concatenate((numerical_train_1,numerical_train_2,numerical_train_3,numerical_train_4,numerical_train_5,numerical_train_6,numerical_train_7,numerical_train_8,numerical_train_9,numerical_train_10),axis=1)\n",
        "num_cv=np.concatenate((numerical_cv_1,numerical_cv_2,numerical_cv_3,numerical_cv_4,numerical_cv_5,numerical_cv_6,numerical_cv_7,numerical_cv_8,numerical_cv_9,numerical_cv_10),axis=1)\n",
        "num_te=np.concatenate((numerical_te_1,numerical_te_2,numerical_te_3,numerical_te_4,numerical_te_5,numerical_te_6,numerical_te_7,numerical_te_8,numerical_te_9,numerical_te_10),axis=1)\n",
        "num_test=np.concatenate((numerical_test_1,numerical_test_2,numerical_test_3,numerical_test_4,numerical_test_5,numerical_test_6,numerical_test_7,numerical_test_8,numerical_test_9,numerical_test_10),axis=1)\n",
        "\n",
        "numerical=StandardScaler()\n",
        "numerical_train=numerical.fit_transform(num_tr)\n",
        "numerical_cv=numerical.transform(num_cv)\n",
        "numerical_te=numerical.transform(num_te)\n",
        "numerical_test=numerical.transform(num_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHIlaHh8HVEB",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Model Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqXIP7WNx4tt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_FILES = [\n",
        "    '/content/drive/My Drive/jigsaw/crawl-300d-2M.gensim',\n",
        "    '/content/drive/My Drive/jigsaw/glove.840B.300d.gensim'\n",
        "]\n",
        "NUM_MODELS = 2\n",
        "BATCH_SIZE = 512\n",
        "LSTM_UNITS = 128\n",
        "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
        "EPOCHS = 4\n",
        "MAX_LEN = 220\n",
        "IDENTITY_COLUMNS = ['male', 'female', 'homosexual_gay_or_lesbian', 'christian', 'jewish', 'muslim', 'black', 'white', 'psychiatric_or_mental_illness']\n",
        "\n",
        "TEXT_COLUMN = 'comment_text'\n",
        "TARGET_COLUMN='target'\n",
        "CHARS_TO_REMOVE = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n“”’\\'∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—'\n",
        "\n",
        "x_train = X_train[TEXT_COLUMN].astype(str)\n",
        "y_train = X_train[TARGET_COLUMN].values\n",
        "\n",
        "x_cv = X_cv[TEXT_COLUMN].astype(str)\n",
        "y_cv = X_cv[TARGET_COLUMN].values\n",
        "\n",
        "x_te = X_te[TEXT_COLUMN].astype(str)\n",
        "x_test = test[TEXT_COLUMN].astype(str)\n",
        "\n",
        "for column in IDENTITY_COLUMNS + [TARGET_COLUMN]:\n",
        "    X_train[column] = np.where(X_train[column] >= 0.5, True, False)\n",
        "    X_cv[column] = np.where(X_cv[column] >= 0.5, True, False)\n",
        "    X_te[column] = np.where(X_te[column] >= 0.5, True, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYVfMA7Vx5Zs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = text.Tokenizer(filters=CHARS_TO_REMOVE, lower=False)\n",
        "tokenizer.fit_on_texts(list(x_train))\n",
        "\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_cv = tokenizer.texts_to_sequences(x_cv)\n",
        "x_te = tokenizer.texts_to_sequences(x_te)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)\n",
        "\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=MAX_LEN)\n",
        "x_cv = sequence.pad_sequences(x_cv, maxlen=MAX_LEN)\n",
        "x_te = sequence.pad_sequences(x_te, maxlen=MAX_LEN)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6laVWzsJIKZh",
        "colab_type": "code",
        "outputId": "06f9e4eb-8b8c-4896-9481-8bf4438e78d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "def build_matrix(word_index, path):\n",
        "    ''' this function prepares embedding matrix'''\n",
        "    embedding_index = KeyedVectors.load(path, mmap='r')\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "    for word, i in word_index.items():\n",
        "        for candidate in [word, word.lower()]:\n",
        "            if candidate in embedding_index:\n",
        "                embedding_matrix[i] = embedding_index[candidate]\n",
        "                break\n",
        "    return embedding_matrix\n",
        "\n",
        "sample_weights = np.ones(len(x_train), dtype=np.float32)\n",
        "sample_weights += X_train[IDENTITY_COLUMNS].sum(axis=1)\n",
        "sample_weights += X_train[TARGET_COLUMN] * (~X_train[IDENTITY_COLUMNS]).sum(axis=1)\n",
        "sample_weights += (~X_train[TARGET_COLUMN]) * X_train[IDENTITY_COLUMNS].sum(axis=1) * 5\n",
        "sample_weights /= sample_weights.mean()\n",
        "\n",
        "embedding_matrix = np.concatenate([build_matrix(tokenizer.word_index, f) for f in EMBEDDING_FILES], axis=-1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning:\n",
            "\n",
            "This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cylHoFfRywPr",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Model 2 : Dropout 0.2 + text feature + Additional Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pQKqnyMwmqt",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=149CK11fzBekwRp57TcBShUdacGsCUO6P)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TK759jVk5Kfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(embedding_matrix):\n",
        "    words = Input(shape=(None,),name=\"text_feature\")\n",
        "    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n",
        "    x = SpatialDropout1D(0.2)(x)\n",
        "    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "    \n",
        "    numerical_feats = Input(shape=(10,),name=\"numerical_features\")\n",
        "    numerical_featss = Dense(256,activation=\"relu\",kernel_initializer=\"he_normal\")(numerical_feats)\n",
        "\n",
        "    hidden = concatenate([GlobalMaxPooling1D()(x),GlobalAveragePooling1D()(x),numerical_featss,])\n",
        "    hidden = add([hidden, Dense(768, activation='relu')(hidden)])\n",
        "    hidden = add([hidden, Dense(768, activation='relu')(hidden)])\n",
        "    result = Dense(1, activation='sigmoid')(hidden)\n",
        "    \n",
        "    model = Model(inputs=[words,numerical_feats], outputs=[result])#, aux_result])\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    plot_model(model, to_file='/content/drive/My Drive/jigsaw/Model2.png', show_shapes=True) \n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdF5FfDgkJWb",
        "colab_type": "code",
        "outputId": "dad0a609-e948-4200-f548-c0a2c47e81d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "#all epochs to fit once\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "checkpoint = tensorflow.keras.callbacks.ModelCheckpoint('/content/drive/My Drive/jigsaw/Model22.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min') \n",
        "log_dir=\"/content/drive/My Drive/jigsaw/Model22/logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,write_grads=True)\n",
        "model = build_model(embedding_matrix)\n",
        "model.fit([x_train,numerical_train], y_train,batch_size=BATCH_SIZE,epochs=5,verbose=2,validation_data=([x_cv,numerical_cv],y_cv),callbacks=[tensorboard_callback,checkpoint],sample_weight=[sample_weights.values, np.ones_like(sample_weights)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-31 12:09:21,855 : WARNING : `write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.25208, saving model to /content/drive/My Drive/jigsaw/Model22.hdf5\n",
            "2856/2856 - 915s - loss: 0.4270 - val_loss: 0.2521\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.25208 to 0.24228, saving model to /content/drive/My Drive/jigsaw/Model22.hdf5\n",
            "2856/2856 - 818s - loss: 0.4096 - val_loss: 0.2423\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.24228\n",
            "2856/2856 - 816s - loss: 0.4045 - val_loss: 0.2423\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.24228 to 0.23914, saving model to /content/drive/My Drive/jigsaw/Model22.hdf5\n",
            "2856/2856 - 826s - loss: 0.4002 - val_loss: 0.2391\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.23914 to 0.23825, saving model to /content/drive/My Drive/jigsaw/Model22.hdf5\n",
            "2856/2856 - 821s - loss: 0.3964 - val_loss: 0.2382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f75ee0ca128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3kC4Y1czNsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir='/content/drive/My Drive/jigsaw/Model22/logs/fit'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUqkcboi730n",
        "colab_type": "code",
        "outputId": "a12fa49b-bacf-4af6-dec7-1b5d042fbea2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# load the model \n",
        "model1=tensorflow.keras.models.load_model('/content/drive/My Drive/jigsaw/Model22.hdf5')\n",
        "MODEL_NAME = 'with_DO1'\n",
        "X_te[MODEL_NAME] =model1.predict([x_te,numerical_te], batch_size=2048).flatten() \n",
        "bias_metrics_df = compute_bias_metrics_for_model(X_te, IDENTITY_COLUMNS, MODEL_NAME, TARGET_COLUMN)\n",
        "get_final_metric(bias_metrics_df, calculate_overall_auc(X_te, MODEL_NAME))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.932494270491741"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CpQ3wJiV1Q5",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Model 3: Without Dropout  + text feature + Additional Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSYjhK7W85tn",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=1pQmBx6ngX1nJ4OaiL6GBtWsXa7ErTia_)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpNZpJppV5Qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(embedding_matrix):\n",
        "    words = Input(shape=(None,),name=\"text_feature\")\n",
        "    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n",
        "    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "    \n",
        "    numerical_feats = Input(shape=(10,),name=\"numerical_features\")\n",
        "    numerical_featss = Dense(256,activation=\"relu\",kernel_initializer=\"he_normal\")(numerical_feats)\n",
        "\n",
        "    hidden = concatenate([GlobalMaxPooling1D()(x),GlobalAveragePooling1D()(x),numerical_featss,])\n",
        "    hidden = add([hidden, Dense(768, activation='relu')(hidden)])\n",
        "    hidden = add([hidden, Dense(768, activation='relu')(hidden)])\n",
        "    result = Dense(1, activation='sigmoid')(hidden)\n",
        "    \n",
        "    model = Model(inputs=[words,numerical_feats], outputs=result)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    plot_model(model, to_file='/content/drive/My Drive/jigsaw/model33.png', show_shapes=True) \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-nzJNQEc32A",
        "colab_type": "code",
        "outputId": "eaa06ea0-87c8-4639-fe22-2e6c5581d717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#all epochs to fit once\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "checkpoint = tensorflow.keras.callbacks.ModelCheckpoint('/content/drive/My Drive/jigsaw/Model33.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min') \n",
        "log_dir=\"/content/drive/My Drive/jigsaw/Model33/logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,write_grads=True)\n",
        "model = build_model(embedding_matrix)\n",
        "model.fit([x_train,numerical_train], y_train,batch_size=BATCH_SIZE,epochs=15,verbose=2,validation_data=([x_cv,numerical_cv],y_cv),callbacks=[tensorboard_callback,checkpoint],sample_weight=[sample_weights.values, np.ones_like(sample_weights)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-06-01 05:37:32,131 : WARNING : `write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.23934, saving model to /content/drive/My Drive/jigsaw/Model33.hdf5\n",
            "2856/2856 - 776s - loss: 0.4260 - val_loss: 0.2393\n",
            "Epoch 2/15\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.23934\n",
            "2856/2856 - 767s - loss: 0.4070 - val_loss: 0.2395\n",
            "Epoch 3/15\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.23934 to 0.23773, saving model to /content/drive/My Drive/jigsaw/Model33.hdf5\n",
            "2856/2856 - 772s - loss: 0.4009 - val_loss: 0.2377\n",
            "Epoch 4/15\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.23773 to 0.23526, saving model to /content/drive/My Drive/jigsaw/Model33.hdf5\n",
            "2856/2856 - 773s - loss: 0.3952 - val_loss: 0.2353\n",
            "Epoch 5/15\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.23526\n",
            "2856/2856 - 768s - loss: 0.3895 - val_loss: 0.2416\n",
            "Epoch 6/15\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.23526\n",
            "2856/2856 - 769s - loss: 0.3838 - val_loss: 0.2380\n",
            "Epoch 7/15\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.23526\n",
            "2856/2856 - 768s - loss: 0.3784 - val_loss: 0.2405\n",
            "Epoch 8/15\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.23526\n",
            "2856/2856 - 768s - loss: 0.3732 - val_loss: 0.2396\n",
            "Epoch 9/15\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.23526\n",
            "2856/2856 - 768s - loss: 0.3691 - val_loss: 0.2394\n",
            "Epoch 10/15\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.23526\n",
            "2856/2856 - 768s - loss: 0.3656 - val_loss: 0.2437\n",
            "Epoch 11/15\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.23526\n",
            "2856/2856 - 768s - loss: 0.3628 - val_loss: 0.2428\n",
            "Epoch 12/15\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.23526\n",
            "2856/2856 - 768s - loss: 0.3606 - val_loss: 0.2427\n",
            "Epoch 13/15\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.23526\n",
            "2856/2856 - 768s - loss: 0.3590 - val_loss: 0.2437\n",
            "Epoch 14/15\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.23526\n",
            "2856/2856 - 769s - loss: 0.3578 - val_loss: 0.2423\n",
            "Epoch 15/15\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.23526\n",
            "2856/2856 - 768s - loss: 0.3567 - val_loss: 0.2455\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f31143fb9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C3cTs6fzQpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir='/content/drive/My Drive/jigsaw/Model33/logs/fit'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpSlzrF0Fr60",
        "colab_type": "code",
        "outputId": "98f10998-5e33-4924-f22f-e8835ddeb779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# load the model \n",
        "model1=tensorflow.keras.models.load_model('/content/drive/My Drive/jigsaw/Model33.hdf5')\n",
        "MODEL_NAME = 'withoutDP'\n",
        "X_te[MODEL_NAME] =model1.predict([x_te,numerical_te], batch_size=2048).flatten() \n",
        "bias_metrics_df = compute_bias_metrics_for_model(X_te, IDENTITY_COLUMNS, MODEL_NAME, TARGET_COLUMN)\n",
        "get_final_metric(bias_metrics_df, calculate_overall_auc(X_te, MODEL_NAME))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.930495739941519"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qEZYRg-P6zc",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Model 4: With 0.5 Dropout  + text feature + Additional Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf9c0VBwdKoO",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?id=11W8r0J4lTa9LXuySbNfnFxpaSd1ERaNe)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUWN_fCDP7FA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(embedding_matrix):\n",
        "    words = Input(shape=(None,),name=\"text_feature\")\n",
        "    x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n",
        "    x = SpatialDropout1D(0.5)(x)\n",
        "    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "    x = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences=True))(x)\n",
        "    \n",
        "    numerical_feats = Input(shape=(10,),name=\"numerical_features\")\n",
        "    numerical_featss = Dense(256,activation=\"relu\",kernel_initializer=\"he_normal\")(numerical_feats)\n",
        "\n",
        "    hidden = concatenate([GlobalMaxPooling1D()(x),GlobalAveragePooling1D()(x),numerical_featss,])\n",
        "    hidden = add([hidden, Dense(768, activation='relu')(hidden)])\n",
        "    hidden = add([hidden, Dense(768, activation='relu')(hidden)])\n",
        "    result = Dense(1, activation='sigmoid')(hidden)\n",
        "    \n",
        "    model = Model(inputs=[words,numerical_feats], outputs=result)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    plot_model(model, to_file='/content/drive/My Drive/jigsaw/model44.png', show_shapes=True) \n",
        "   \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J23GxewvQytL",
        "colab_type": "code",
        "outputId": "97ac88ab-2671-4b72-d078-5b3e8ed1b60f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "checkpoint = tensorflow.keras.callbacks.ModelCheckpoint('/content/drive/My Drive/jigsaw/Model44.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='min') \n",
        "log_dir=\"/content/drive/My Drive/jigsaw/Model44/logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True,write_grads=True)\n",
        "model = build_model(embedding_matrix)\n",
        "model.fit([x_train,numerical_train], y_train,batch_size=BATCH_SIZE,epochs=5,verbose=2,validation_data=([x_cv,numerical_cv],y_cv),callbacks=[tensorboard_callback,checkpoint],sample_weight=[sample_weights.values, np.ones_like(sample_weights)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-06-01 08:59:33,564 : WARNING : `write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.25312, saving model to /content/drive/My Drive/jigsaw/Model44.hdf5\n",
            "2856/2856 - 793s - loss: 0.4400 - val_loss: 0.2531\n",
            "Epoch 2/5\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.25312 to 0.25297, saving model to /content/drive/My Drive/jigsaw/Model44.hdf5\n",
            "2856/2856 - 794s - loss: 0.4153 - val_loss: 0.2530\n",
            "Epoch 3/5\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.25297\n",
            "2856/2856 - 788s - loss: 0.4106 - val_loss: 0.2542\n",
            "Epoch 4/5\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.25297 to 0.25020, saving model to /content/drive/My Drive/jigsaw/Model44.hdf5\n",
            "2856/2856 - 793s - loss: 0.4076 - val_loss: 0.2502\n",
            "Epoch 5/5\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.25020 to 0.24852, saving model to /content/drive/My Drive/jigsaw/Model44.hdf5\n",
            "2856/2856 - 794s - loss: 0.4053 - val_loss: 0.2485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3099134438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Kc5qREzTOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir='/content/drive/My Drive/jigsaw/Model44/logs/fit'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix1ELQgvRs8r",
        "colab_type": "code",
        "outputId": "0c7540c9-9f92-48ad-ebd4-264e66c6603a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# load the model \n",
        "model1=tensorflow.keras.models.load_model('/content/drive/My Drive/jigsaw/Model44.hdf5')\n",
        "MODEL_NAME = 'DP'\n",
        "X_te[MODEL_NAME] =model1.predict([x_te,numerical_te], batch_size=2048).flatten() \n",
        "bias_metrics_df = compute_bias_metrics_for_model(X_te, IDENTITY_COLUMNS, MODEL_NAME, TARGET_COLUMN)\n",
        "get_final_metric(bias_metrics_df, calculate_overall_auc(X_te, MODEL_NAME))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9317927713596027"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8FqpJQqyz6O",
        "colab_type": "text"
      },
      "source": [
        "### From above trained models Model 2(Dropout 0.2 + text feature + Additional Features)has given us high score.so lets load that trained model and predict on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JNKtHnjzNdd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('/content/drive/My Drive/test.csv')\n",
        "x_test=pickle.load(open('/content/drive/My Drive/jigsaw/xtest','rb'))\n",
        "numerical_test=pickle.load(open('/content/drive/My Drive/jigsaw/numericaltest','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9d0p8ruy-jT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the model \n",
        "model1=tensorflow.keras.models.load_model('/content/drive/My Drive/jigsaw/Model22.hdf5')\n",
        "predictions=model1.predict([x_test,numerical_test], batch_size=2048).flatten() \n",
        "\n",
        "submission = pd.DataFrame.from_dict({\n",
        "    'id': test.id,\n",
        "    'prediction': predictions\n",
        "})\n",
        "submission.to_csv('/content/drive/My Drive/jigsaw/submission.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUt-jVrh-k-x",
        "colab_type": "text"
      },
      "source": [
        "**On kaggle kernel we got a score of 0.93112**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-C4XajRBA5u",
        "colab_type": "text"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMvEfx7bKRYk",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDojdebyKPlT",
        "colab_type": "code",
        "outputId": "5ad4c499-0732-493a-aebe-f4c33d95d066",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "import pandas as pd \n",
        "   \n",
        "x = PrettyTable()\n",
        "x.field_names = [\"Model\", \"ROC-AUC Score\", \"Custom  Metric Score\"]\n",
        "x.add_row([\"Logistic Regression\", 0.95,  0.8904733235626956])\n",
        "x.add_row([\"Naive Bayes\\t\", 0.88, 0.837811746713348])\n",
        "x.add_row([\"SVM\\t\",      0.95,   0.8814130929571368])\n",
        "x.add_row([\"Deep Learning\", \" - \\t\",  0.9319064728629746])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------+---------------+----------------------+\n",
            "|        Model        | ROC-AUC Score | Custom  Metric Score |\n",
            "+---------------------+---------------+----------------------+\n",
            "| Logistic Regression |      0.95     |  0.8904733235626956  |\n",
            "|     Naive Bayes\t    |      0.88     |  0.837811746713348   |\n",
            "|         SVM\t        |      0.95     |  0.8814130929571368  |\n",
            "|    Deep Learning    |       - \t     |  0.9319064728629746  |\n",
            "+---------------------+---------------+----------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NzdYkqiO9a-",
        "colab_type": "text"
      },
      "source": [
        "### After adding additional features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb-1ovcPPPKZ",
        "colab_type": "code",
        "outputId": "a5595095-a30e-4d6c-9de6-67499f1a396b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "x = PrettyTable()\n",
        "x.field_names = [\"Model\\t\\t\\t\\t\\t\", \"\\tCustom  Metric Score\"]\n",
        "x.add_row([\"Dropout 0.2 + text feature + Additional Features\\t\\t\", 0.932494270491741])\n",
        "x.add_row([\"Without Dropout + text feature + Additional Features\\t\", 0.930495739941519])\n",
        "x.add_row([\"With 0.5 Dropout + text feature + Additional Features\\t\", 0.9317927713596027])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------+-----------------------+\n",
            "|                       Model\t\t\t\t\t                       | \tCustom  Metric Score |\n",
            "+--------------------------------------------------------+-----------------------+\n",
            "|   Dropout 0.2 + text feature + Additional Features\t\t   |   0.932494270491741   |\n",
            "| Without Dropout + text feature + Additional Features\t  |   0.930495739941519   |\n",
            "| With 0.5 Dropout + text feature + Additional Features\t |   0.9317927713596027  |\n",
            "+--------------------------------------------------------+-----------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhX0C9Q7WmjQ",
        "colab_type": "text"
      },
      "source": [
        "# Conclusion\n",
        "1) As we have seen machine learning models performed very well when we use roc-auc metric but when we used custom metric then it has given compartively low score.</br>\n",
        "2) We have tried three machine learning models out of them Logistic regression has given higher score followed by SVM ,Naive bayes model.</br>\n",
        "3) To improve performance on custom metric we have trained **five** deep learning models out of which model named **\"Dropout 0.2 + text feature + Additional Features\"**which has given **0.9324 on custom metric** ,we can see that this score is much higher than what we got using previous models.\n",
        "4)**After adding those additional features ,we have improved our model from 0.9319064728629746 to  0.932494270491741**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9G-8vqTFprKb"
      },
      "source": [
        "# Step by Step Procedure to solve this case study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vwTRE4YHpxhQ"
      },
      "source": [
        "1) **Business Problem**: First go through business problem, understand problem statement,define business objectives and constraints, understand data fields.</br>\n",
        "2)**Map the real-world problem to a Machine Learning Problem**: understand what type of Machine Learning Problem is this, define performance metric.</br>\n",
        "3)**Work on Exploratory Data Analysis**: like loading data,understanding its toxic and non-toxic features percentage in whole data, knowing toxic and non-toxic words by plotting wordcloud, perform text preprocessing in which replace links with text 'link',decontract words,remove words which contains characters and numbers together,demojize i.e. convert emoji's into words,remove punctuation marks,remove stopwords because having stopwords doesnt help in text classification.</br>\n",
        "4)**Feature Engineering**: we have added 'comment_word_count' ,'comment_char_count' new features after adding we perform univariate analysis by having distribution plot,boxplot,violinplot,kernel density estimate plot and then we visualize using TSNE.</br>\n",
        "5)**Machine Learning Models**<br>\n",
        "- **Train and Cv Split**: we do 80:20 split.</br>\n",
        "- **Make Data Model Ready**: encoding numerical, text features\n",
        "- **Apply ML models**:Tune Hyperparameters of ML models,plot ROC curve and confusion matrix to see how our model is performing and after that use custom metric to see how it will score on kaggle board.</br>\n",
        "\n",
        "6)**Give a try to Deep Learning Model**:build a model ,evauate using custom metric.</br>\n",
        "7)**Summarize Reults**"
      ]
    }
  ]
}